{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模块一：Tensor 的创建与属性 ✨\n",
    "这部分将带您熟悉创建张量的各种方式，并了解如何查看它们的基本属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 导入 PyTorch (★☆☆)\n",
    "任务: 导入 torch 和 numpy 库，并打印各自的版本号，这是使用 PyTorch 的第一步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本: 2.7.0+cu118\n",
      "NumPy 版本: 1.26.3\n"
     ]
    }
   ],
   "source": [
    "# 导入 torch 和 numpy 库\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 打印导入成功信息和版本号\n",
    "print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "print(f\"NumPy 版本: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 从 Python 列表与 NumPy 数组创建 (★☆☆)\n",
    "任务: 将一个 Python 列表 [[1, 2], [3, 4]] 和一个 NumPy 数组 np.array([[5, 6], [7, 8]]) 分别转换为 Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 从列表创建的 Tensor ---\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "--- 从 NumPy 创建的 Tensor ---\n",
      "tensor([[5, 6],\n",
      "        [7, 8]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 定义一个 Python 列表\n",
    "data = [[1, 2], [3, 4]]\n",
    "# 创建一个 NumPy 数组\n",
    "np_arr = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# 从列表创建\n",
    "X = torch.tensor(data)\n",
    "# 从 NumPy 数组创建 (注意：会共享内存)\n",
    "Y = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"--- 从列表创建的 Tensor ---\")\n",
    "print(X)\n",
    "print(\"\\n--- 从 NumPy 创建的 Tensor ---\")\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 创建常量 Tensor (★☆☆)\n",
    "任务: 创建三个形状均为 (2, 3) 的张量：一个全零张量，一个全一张量，以及一个所有元素均为常数 7 的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 全零 Tensor ---\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "--- 全一 Tensor ---\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "--- 填充为 7 的 Tensor ---\n",
      "tensor([[7, 7, 7],\n",
      "        [7, 7, 7]])\n"
     ]
    }
   ],
   "source": [
    "# 定义形状\n",
    "shape = (2, 3)\n",
    "\n",
    "# 创建全零、全一、全为7的张量\n",
    "t_zeros = torch.zeros(shape)\n",
    "t_ones = torch.ones(shape)\n",
    "t_sevens = torch.full(shape, 7)\n",
    "\n",
    "print(\"--- 全零 Tensor ---\")\n",
    "print(t_zeros)\n",
    "print(\"\\n--- 全一 Tensor ---\")\n",
    "print(t_ones)\n",
    "print(\"\\n--- 填充为 7 的 Tensor ---\")\n",
    "print(t_sevens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 获取 Tensor 的核心属性 (★☆☆)\n",
    "任务: 对于给定的张量 X = torch.tensor([[1.0, 2.0], [3.0, 4.0]])，一次性打印出它的形状 (shape)、数据类型 (dtype) 和所在设备 (device)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tensor 的核心属性 ---\n",
      "形状 (Shape): torch.Size([2, 2])\n",
      "数据类型 (dtype): torch.float32\n",
      "所在设备 (device): cpu\n"
     ]
    }
   ],
   "source": [
    "# 创建一个示例张量\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# 获取并打印核心属性\n",
    "print(f\"--- Tensor 的核心属性 ---\")\n",
    "print(f\"形状 (Shape): {X.shape}\")\n",
    "print(f\"数据类型 (dtype): {X.dtype}\")\n",
    "print(f\"所在设备 (device): {X.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 创建指定数据类型的 Tensor (★☆☆)\n",
    "任务: 创建一个形状为 (2, 3)，数据类型为 torch.float16 (半精度浮点) 的全一 Tensor，并验证其数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 创建的 Tensor ---\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float16)\n",
      "\n",
      "--- 验证其数据类型 ---\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# 定义形状和目标数据类型\n",
    "shape = (2, 3)\n",
    "dtype = torch.float16\n",
    "\n",
    "# 在创建时通过 dtype 参数指定数据类型\n",
    "Y = torch.ones(shape, dtype=dtype)\n",
    "\n",
    "print(f\"--- 创建的 Tensor ---\")\n",
    "print(Y)\n",
    "print(f\"\\n--- 验证其数据类型 ---\")\n",
    "print(Y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 仿照其他 Tensor 创建新 Tensor (★☆☆)\n",
    "任务: 给定一个已存在的源张量 src，它的值为 [[1, 2, 3], [4, 5, 6]] 且类型为 float16，请创建一个与它属性（形状、类型、设备）都相同，但值为全零的新 Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 源 Tensor ---\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float16)\n",
      "属性: torch.Size([2, 3]), torch.float16, cpu\n",
      "\n",
      "--- 仿照创建的全零 Tensor ---\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float16)\n",
      "属性: torch.Size([2, 3]), torch.float16, cpu\n"
     ]
    }
   ],
   "source": [
    "# 定义一个源张量\n",
    "src = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float16)\n",
    "\n",
    "# 使用 _like 函数可以方便地复制属性\n",
    "Z = torch.zeros_like(src)\n",
    "\n",
    "print(\"--- 源 Tensor ---\")\n",
    "print(src)\n",
    "print(f\"属性: {src.shape}, {src.dtype}, {src.device}\")\n",
    "print(\"\\n--- 仿照创建的全零 Tensor ---\")\n",
    "print(Z)\n",
    "print(f\"属性: {Z.shape}, {Z.dtype}, {Z.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 创建不同分布的随机 Tensor (★☆☆)\n",
    "任务: 创建两个形状均为 (3, 3) 的随机 Tensor：X 的元素在 [0, 1) 区间均匀分布，Y 的元素服从标准正态分布（均值为0，方差为1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [0, 1) 均匀分布随机 Tensor ---\n",
      "tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009],\n",
      "        [0.2566, 0.7936, 0.9408]])\n",
      "\n",
      "--- 标准正态分布随机 Tensor ---\n",
      "tensor([[ 1.5231,  0.6647, -1.0324],\n",
      "        [-0.2770, -0.1671, -0.1079],\n",
      "        [-1.4285, -0.2810,  0.7489]])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以保证结果可复现\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 定义形状\n",
    "shape = (3, 3)\n",
    "\n",
    "# 创建不同分布的随机张量\n",
    "X = torch.rand(shape)  # 均匀分布\n",
    "Y = torch.randn(shape) # 标准正态分布\n",
    "\n",
    "print(f\"--- [0, 1) 均匀分布随机 Tensor ---\")\n",
    "print(X)\n",
    "print(f\"\\n--- 标准正态分布随机 Tensor ---\")\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. 创建序列 Tensor (★☆☆)\n",
    "任务: 创建两个序列 Tensor：X 是一个从 0 到 10（不含10）、步长为1的整数序列；Y 是一个从 0 到 1（包含1）、均匀划分成5个元素的浮点数序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- arange 创建的整数序列 ---\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "--- linspace 创建的等差序列 ---\n",
      "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# 使用 arange 创建整数序列 (不含结束点)\n",
    "X = torch.arange(0, 10)\n",
    "\n",
    "# 使用 linspace 创建等差序列 (包含结束点)\n",
    "# 参数: start, end, steps\n",
    "Y = torch.linspace(0, 1, 5)\n",
    "\n",
    "print(\"--- arange 创建的整数序列 ---\")\n",
    "print(X)\n",
    "print(\"\\n--- linspace 创建的等差序列 ---\")\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. 在指定设备上创建 Tensor (★☆☆)\n",
    "任务: 检查您的环境中 CUDA (GPU) 是否可用，如果可用，则在第一个 GPU (cuda:0) 上创建一个 2x2 的全一张量；否则，在 CPU 上创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 创建的 Tensor ---\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], device='cuda:0')\n",
      "它所在的设备是: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 检查 CUDA 是否可用\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 使用 device 参数在指定设备上创建张量\n",
    "Z = torch.ones(2, 2, device=device)\n",
    "\n",
    "print(f\"\\n--- 创建的 Tensor ---\")\n",
    "print(Z)\n",
    "print(f\"它所在的设备是: {Z.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模块二：索引、切片与形状变换 🔪\n",
    "掌握了如何创建 Tensor 后，下一步是学习如何灵活地访问和重塑它们。这是数据预处理和特征工程中的核心技能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 基础索引：访问特定元素 (★☆☆)\n",
    "任务: 创建一个 3x3 的序列张量 X，其值为 0 到 8。然后，访问并打印出位于第 2 行、第 1 列的元素（注意索引从0开始）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "\n",
      "--- 第2行、第1列的元素是 ---\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 3x3 的张量\n",
    "X = torch.arange(9).reshape(3, 3)\n",
    "\n",
    "# 访问第 2 行 (索引为1), 第 1 列 (索引为0) 的元素\n",
    "element = X[1, 0]\n",
    "\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(X)\n",
    "print(f\"\\n--- 第2行、第1列的元素是 ---\")\n",
    "print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. 基础切片：提取整行与整列 (★☆☆)\n",
    "任务: 对于一个 4x4 的序列张量 Y（值为0-15），提取并打印出它的第 3 整行和第 4 整列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "\n",
      "--- 第 3 行 ---\n",
      "tensor([ 8,  9, 10, 11])\n",
      "\n",
      "--- 第 4 列 ---\n",
      "tensor([ 3,  7, 11, 15])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 4x4 的张量\n",
    "Y = torch.arange(16).reshape(4, 4)\n",
    "\n",
    "# 提取第 3 行 (索引为2)\n",
    "third_row = Y[2, :] # 或者 Y[2]\n",
    "\n",
    "# 提取第 4 列 (索引为3)\n",
    "fourth_col = Y[:, 3]\n",
    "\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(Y)\n",
    "print(\"\\n--- 第 3 行 ---\")\n",
    "print(third_row)\n",
    "print(\"\\n--- 第 4 列 ---\")\n",
    "print(fourth_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. 进阶切片：提取子矩阵 (★☆☆)\n",
    "任务: 对于一个 5x5 的序列张量 Z（值为0-24），提取出由第3、4行和第2、3、4列共同构成的 2x3 子矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "\n",
      "--- 提取的 2x3 子矩阵 ---\n",
      "tensor([[11, 12, 13],\n",
      "        [16, 17, 18]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 5x5 的张量\n",
    "Z = torch.arange(25).reshape(5, 5)\n",
    "\n",
    "# 提取子矩阵：行索引为 2, 3；列索引为 1, 2, 3\n",
    "sub_matrix = Z[2:4, 1:4]\n",
    "\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(Z)\n",
    "print(\"\\n--- 提取的 2x3 子矩阵 ---\")\n",
    "print(sub_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. 布尔索引：筛选满足条件的元素 (★☆☆)\n",
    "任务: 创建一个 4x4 的随机整数张量 X（值在0-9之间），筛选出所有大于5的元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([[7, 5, 2, 7],\n",
      "        [2, 5, 7, 2],\n",
      "        [1, 5, 6, 3],\n",
      "        [1, 0, 6, 3]])\n",
      "\n",
      "--- 大于 5 的元素 ---\n",
      "tensor([7, 7, 7, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以保证结果可复现\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# 创建一个 4x4 的随机整数张量\n",
    "X = torch.randint(0, 10, (4, 4))\n",
    "\n",
    "# 创建布尔掩码 (Mask)\n",
    "mask = X > 5\n",
    "\n",
    "# 使用掩码进行索引，筛选出符合条件的元素\n",
    "filtered_elements = X[mask]\n",
    "\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(X)\n",
    "print(\"\\n--- 大于 5 的元素 ---\")\n",
    "print(filtered_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. 使用布尔索引进行原地修改 (★☆☆)\n",
    "任务: 创建一个 3x4 的标准正态分布随机张量 Y，然后将其中所有小于0的元素都原地修改为0（这类似于ReLU激活函数的操作）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([[-1.2061,  0.0617,  1.1632, -1.5008],\n",
      "        [-1.5944, -0.0187, -2.1325, -0.5270],\n",
      "        [-0.1021,  0.0099, -0.4454, -1.4976]])\n",
      "\n",
      "--- 修改后的 Tensor ---\n",
      "tensor([[0.0000, 0.0617, 1.1632, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0099, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(20)\n",
    "\n",
    "# 创建一个 3x4 的随机张量\n",
    "Y = torch.randn(3, 4)\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(Y)\n",
    "\n",
    "# 使用布尔索引找到小于0的元素，并原地赋值为0\n",
    "Y[Y < 0] = 0\n",
    "\n",
    "print(\"\\n--- 修改后的 Tensor ---\")\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. 改变形状 (★☆☆)\n",
    "任务: 创建一个值为 0-11 的一维张量 Z，然后将其形状变为 3x4。请分别使用两种不同的方法实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "\n",
      "--- 使用 .view() 的结果 ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "--- 使用 .reshape() 的结果 ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个一维张量\n",
    "Z = torch.arange(12)\n",
    "\n",
    "# 使用 .view() 改变形状\n",
    "# .view() 要求原始张量的内存是连续的\n",
    "Z_view = Z.view(3, 4)\n",
    "\n",
    "# 使用 .reshape() 改变形状\n",
    "# .reshape() 更灵活，如果内存不连续，它会先创建副本再改变形状\n",
    "Z_reshape = Z.reshape(3, 4)\n",
    "\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(Z)\n",
    "print(\"\\n--- 使用 .view() 的结果 ---\")\n",
    "print(Z_view)\n",
    "print(\"\\n--- 使用 .reshape() 的结果 ---\")\n",
    "print(Z_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. 增加维度 (★☆☆)\n",
    "任务: 创建一个形状为 (3, 4) 的张量 X。在第1个维度（dim=0）和第3个维度（dim=2）上增加一个新维度，使其最终形状变为 (1, 3, 1, 4)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor (shape: torch.Size([3, 4])) ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "--- 在 dim=0 unsqueeze 后 (shape: torch.Size([1, 3, 4])) ---\n",
      "--- 在 dim=2 unsqueeze 后 (shape: torch.Size([1, 3, 1, 4])) ---\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 3x4 的张量\n",
    "X = torch.arange(12).reshape(3, 4)\n",
    "print(f\"--- 原始 Tensor (shape: {X.shape}) ---\")\n",
    "print(X)\n",
    "\n",
    "# 在第 1 个维度 (dim=0) 增加维度\n",
    "X_unsqueezed_1 = X.unsqueeze(0)\n",
    "print(f\"\\n--- 在 dim=0 unsqueeze 后 (shape: {X_unsqueezed_1.shape}) ---\")\n",
    "\n",
    "# 在第 3 个维度 (dim=2) 增加维度\n",
    "X_unsqueezed_2 = X_unsqueezed_1.unsqueeze(2)\n",
    "print(f\"--- 在 dim=2 unsqueeze 后 (shape: {X_unsqueezed_2.shape}) ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. 压缩维度 (★☆☆)\n",
    "任务: 创建一个形状为 (1, 3, 1, 2) 的随机张量 Y，移除所有大小为1的维度，使其最终形状变为 (3, 2)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor (shape: torch.Size([1, 3, 1, 2])) ---\n",
      "tensor([[[[0.4489, 0.2113]],\n",
      "\n",
      "         [[0.6839, 0.7478]],\n",
      "\n",
      "         [[0.4627, 0.7742]]]])\n",
      "\n",
      "--- squeeze 后的 Tensor (shape: torch.Size([3, 2])) ---\n",
      "tensor([[0.4489, 0.2113],\n",
      "        [0.6839, 0.7478],\n",
      "        [0.4627, 0.7742]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个包含冗余维度的张量\n",
    "Y = torch.rand(1, 3, 1, 2)\n",
    "\n",
    "# 使用 .squeeze() 移除所有大小为1的维度\n",
    "Y_squeezed = Y.squeeze()\n",
    "\n",
    "print(f\"--- 原始 Tensor (shape: {Y.shape}) ---\")\n",
    "print(Y)\n",
    "print(f\"\\n--- squeeze 后的 Tensor (shape: {Y_squeezed.shape}) ---\")\n",
    "print(Y_squeezed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. 交换维度 (★☆☆)\n",
    "任务: 在深度学习中，图像张量通常以 (C, H, W)（通道, 高, 宽）格式存储。请创建一个形状为 (3, 224, 224) 的模拟图像张量 Z，并将其维度转换为 (H, W, C)，以方便图像显示，可以尝试多种方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor 形状 (C, H, W) ---\n",
      "torch.Size([3, 224, 224])\n",
      "\n",
      "--- permute 后的 Tensor 形状 (H, W, C) ---\n",
      "torch.Size([224, 224, 3])\n",
      "\n",
      "--- transpose 后的 Tensor 形状 (H, W, C) ---\n",
      "torch.Size([224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个模拟图像张量 (通道, 高, 宽)\n",
    "C, H, W = 3, 224, 224\n",
    "Z = torch.randn(C, H, W)\n",
    "\n",
    "# 使用 .permute() 交换维度\n",
    "# 将 (0, 1, 2) -> (1, 2, 0)\n",
    "Z_permuted = Z.permute(1, 2, 0)\n",
    "\n",
    "# 使用 .transpose() 交换维度\n",
    "Z_transpose = Z.transpose(0, 1).transpose(1, 2)\n",
    "\n",
    "\n",
    "print(f\"--- 原始 Tensor 形状 (C, H, W) ---\")\n",
    "print(Z.shape)\n",
    "print(f\"\\n--- permute 后的 Tensor 形状 (H, W, C) ---\")\n",
    "print(Z_permuted.shape)\n",
    "print(f\"\\n--- transpose 后的 Tensor 形状 (H, W, C) ---\")\n",
    "print(Z_transpose.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. 沿现有维度拼接张量 (★☆☆)\n",
    "任务: 创建两个形状均为 (2, 3) 的张量 X ∈ [0,6) 和 Y ∈ [6,12)。将它们分别沿维度0（行方向）和维度1（列方向）进行拼接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor X ---\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "--- 原始 Tensor Y ---\n",
      "tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "\n",
      "--- 沿 dim=0 拼接 (结果形状: 4x3) ---\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "\n",
      "--- 沿 dim=1 拼接 (结果形状: 2x6) ---\n",
      "tensor([[ 0,  1,  2,  6,  7,  8],\n",
      "        [ 3,  4,  5,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 创建两个 2x3 的张量\n",
    "X = torch.arange(6).reshape(2, 3)\n",
    "Y = torch.arange(6, 12).reshape(2, 3)\n",
    "\n",
    "# 沿维度0 (行) 拼接\n",
    "cat_dim0 = torch.cat((X, Y), dim=0)\n",
    "\n",
    "# 沿维度1 (列) 拼接\n",
    "cat_dim1 = torch.cat((X, Y), dim=1)\n",
    "\n",
    "print(\"--- 原始 Tensor X ---\")\n",
    "print(X)\n",
    "print(\"\\n--- 原始 Tensor Y ---\")\n",
    "print(Y)\n",
    "print(\"\\n--- 沿 dim=0 拼接 (结果形状: 4x3) ---\")\n",
    "print(cat_dim0)\n",
    "print(\"\\n--- 沿 dim=1 拼接 (结果形状: 2x6) ---\")\n",
    "print(cat_dim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20. 沿新维度堆叠张量 (★☆☆)\n",
    "任务: 创建两个形状均为 (2, 3) 的张量 X 和 Y。将它们堆叠起来，创建一个新的维度，使结果张量的形状变为 (2, 2, 3)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor X (shape: 2x3) ---\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "--- 原始 Tensor Y (shape: 2x3) ---\n",
      "tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "\n",
      "--- 堆叠后的 Tensor (结果形状: 2x2x3) ---\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "堆叠后形状: torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 重新创建两个 2x3 的张量\n",
    "X = torch.arange(6).reshape(2, 3)\n",
    "Y = torch.arange(6, 12).reshape(2, 3)\n",
    "\n",
    "# 沿一个新维度 (dim=0) 进行堆叠\n",
    "stacked_tensor = torch.stack((X, Y), dim=0)\n",
    "\n",
    "print(\"--- 原始 Tensor X (shape: 2x3) ---\")\n",
    "print(X)\n",
    "print(\"\\n--- 原始 Tensor Y (shape: 2x3) ---\")\n",
    "print(Y)\n",
    "print(\"\\n--- 堆叠后的 Tensor (结果形状: 2x2x3) ---\")\n",
    "print(stacked_tensor)\n",
    "print(f\"堆叠后形状: {stacked_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21. 分割张量：精确控制与便捷分割 (★★☆)\n",
    "任务: 对一个7x4的张量Z，将其沿行（dim=0）均匀分割成2块（可以尝试两种方法），再将第一个块其沿行（dim=0）分割成不等大小的块[1,3]，PyTorch会自动处理不能整除的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 用于分割的原始 Tensor (7x4) ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19],\n",
      "        [20, 21, 22, 23],\n",
      "        [24, 25, 26, 27]])\n",
      "--- chunk 分割成的2个块 ---\n",
      "(tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]]), tensor([[16, 17, 18, 19],\n",
      "        [20, 21, 22, 23],\n",
      "        [24, 25, 26, 27]]))\n",
      "--- split 分割成的2个块 ---\n",
      "(tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]]), tensor([[16, 17, 18, 19],\n",
      "        [20, 21, 22, 23],\n",
      "        [24, 25, 26, 27]]))\n",
      "--- split 分割成不等大小的块 (分别为1, 3行) ---\n",
      "(tensor([[0, 1, 2, 3]]), tensor([[ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]]))\n"
     ]
    }
   ],
   "source": [
    "Z = torch.arange(28).reshape(7, 4)\n",
    "print(\"--- 用于分割的原始 Tensor (7x4) ---\")\n",
    "print(Z)\n",
    "\n",
    "# 将张量沿 dim=0 分割成大小分别为2块\n",
    "chunks = torch.chunk(Z, 2, dim=0)\n",
    "print(\"--- chunk 分割成的2个块 ---\")\n",
    "print(chunks)\n",
    "\n",
    "# 将张量沿 dim=0 分割成大小分别为2块(这里的4指的是每块大小为4)\n",
    "splits = torch.split(Z, 4, dim=0)\n",
    "print(\"--- split 分割成的2个块 ---\")\n",
    "print(splits)\n",
    "\n",
    "# 将第一个块沿 dim=0 分割成不等大小的块\n",
    "unequal_chunks = torch.split(chunks[0], [1, 3], dim=0)\n",
    "print(\"--- split 分割成不等大小的块 (分别为1, 3行) ---\")\n",
    "print(unequal_chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22. 综合运用：重塑与拼接 (★★☆)\n",
    "任务: 假设你有一个批次的数据 (Batch, Features)，形状为 (4, 10)。你需要将其分成两组，每组2个样本，分别进行不同的处理（这里可以用乘以不同常数模拟×2 or ×3），然后再将处理后的结果合并起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始批次数据 (4x10) ---\n",
      "torch.Size([4, 10])\n",
      "tensor([[7, 5, 2, 7, 2, 5, 7, 2, 1, 5],\n",
      "        [6, 3, 1, 0, 6, 3, 4, 0, 6, 2],\n",
      "        [8, 9, 2, 0, 9, 9, 4, 4, 9, 4],\n",
      "        [4, 5, 4, 0, 8, 9, 3, 0, 9, 3]])\n",
      "\n",
      "--- 分割后的两组 (均为 2x10) ---\n",
      "组1形状: torch.Size([2, 10]), 组2形状: torch.Size([2, 10])\n",
      "tensor([[7, 5, 2, 7, 2, 5, 7, 2, 1, 5],\n",
      "        [6, 3, 1, 0, 6, 3, 4, 0, 6, 2]])\n",
      "tensor([[8, 9, 2, 0, 9, 9, 4, 4, 9, 4],\n",
      "        [4, 5, 4, 0, 8, 9, 3, 0, 9, 3]])\n",
      "\n",
      "--- 重新拼接后的最终批次 (4x10) ---\n",
      "torch.Size([4, 10])\n",
      "tensor([[14, 10,  4, 14,  4, 10, 14,  4,  2, 10],\n",
      "        [12,  6,  2,  0, 12,  6,  8,  0, 12,  4],\n",
      "        [24, 27,  6,  0, 27, 27, 12, 12, 27, 12],\n",
      "        [12, 15, 12,  0, 24, 27,  9,  0, 27,  9]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "# 创建一个模拟的批次数据\n",
    "batch_data = torch.randint(0, 10, (4, 10))\n",
    "\n",
    "# 1. 将数据分割成两组\n",
    "group1, group2 = torch.chunk(batch_data, 2, dim=0)\n",
    "\n",
    "# 2. 模拟对两组数据进行不同的处理\n",
    "processed_group1 = group1 * 2\n",
    "processed_group2 = group2 * 3\n",
    "\n",
    "# 3. 将处理后的结果重新拼接成一个批次\n",
    "final_batch = torch.cat((processed_group1, processed_group2), dim=0)\n",
    "\n",
    "print(\"--- 原始批次数据 (4x10) ---\")\n",
    "print(batch_data.shape)\n",
    "print(batch_data)\n",
    "print(\"\\n--- 分割后的两组 (均为 2x10) ---\")\n",
    "print(f\"组1形状: {group1.shape}, 组2形状: {group2.shape}\")\n",
    "print(group1)\n",
    "print(group2)\n",
    "print(\"\\n--- 重新拼接后的最终批次 (4x10) ---\")\n",
    "print(final_batch.shape)\n",
    "print(final_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23. 高级索引：按指定索引筛选 (★★☆)\n",
    "任务: 创建一个 5x4 的张量 X（值为0-19）。现在，你有一个包含行索引的 1D 张量tensor([0, 3, 1, 3])。请从 X 中提取出这些索引对应的行，并组成新的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor (5x4) ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19]])\n",
      "\n",
      "--- 指定的行索引 ---\n",
      "tensor([0, 3, 1, 3])\n",
      "\n",
      "--- index_select 提取的结果 ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [12, 13, 14, 15],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [12, 13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 5x4 的张量\n",
    "X = torch.arange(20).reshape(5, 4)\n",
    "# 定义要提取的行索引\n",
    "indices = torch.tensor([0, 3, 1, 3])\n",
    "\n",
    "# 使用 index_select 沿维度 0 (行) 提取\n",
    "selected_rows = torch.index_select(X, dim=0, index=indices)\n",
    "\n",
    "print(\"--- 原始 Tensor (5x4) ---\")\n",
    "print(X)\n",
    "print(\"\\n--- 指定的行索引 ---\")\n",
    "print(indices)\n",
    "print(\"\\n--- index_select 提取的结果 ---\")\n",
    "print(selected_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24. 高级索引：按指定索引收集 (★★★)\n",
    "任务: 给定一个 3x5 的随机int张量 Y，以及一个 3x2 的索引张量 indices。我们需要从 Y 中有选择地提取元素，具体规则是：indices 的每一行包含2个数字，指定从 Y 对应行中应该选择哪些列（例如，如果 indices[0] = [4, 1]，则从 Y 的第 0 行中选择第 4 列和第 1 列的元素），最终结果应该是一个形状为 3x2 的新张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor Y (3x5) ---\n",
      "tensor([[67, 77, 77, 13, 66],\n",
      "        [34, 89, 72, 27, 37],\n",
      "        [45, 76, 61, 45, 59]])\n",
      "\n",
      "--- 要收集的列索引 (3x2) ---\n",
      "tensor([[4, 1],\n",
      "        [0, 2],\n",
      "        [3, 3]])\n",
      "\n",
      "--- 按索引选择的结果 (3x2) ---\n",
      "tensor([[66, 77],\n",
      "        [34, 72],\n",
      "        [45, 45]])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以保证结果可复现\n",
    "torch.manual_seed(30)\n",
    "\n",
    "# 创建一个 3x5 的随机张量\n",
    "Y = torch.randint(10, 100, (3, 5))\n",
    "# 第0行收集第4、1列；第1行收集第0、2列；第2行收集第3、3列\n",
    "indices = torch.tensor([[4, 1], [0, 2], [3, 3]])\n",
    "\n",
    "# 按照索引从原始张量中提取特定元素\n",
    "# 输出形状与索引张量的形状相同\n",
    "gathered_elements = torch.gather(Y, dim=1, index=indices)\n",
    "\n",
    "print(\"--- 原始 Tensor Y (3x5) ---\")\n",
    "print(Y)\n",
    "print(\"\\n--- 要收集的列索引 (3x2) ---\")\n",
    "print(indices)\n",
    "print(\"\\n--- 按索引选择的结果 (3x2) ---\")\n",
    "print(gathered_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25. 条件元素替换与形状保持(★★☆)\n",
    "任务: 创建一个 4x4 的随机整数张量 Z (值在 -5 到 5 之间)。对 Z 中的每个元素应用条件判断，如果元素值大于 0，则保留原始值；如果元素值小于等于 0，则将其替换为 0，输出结果应当保持与输入张量完全相同的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor Z ---\n",
      "tensor([[ 2,  4,  3,  2],\n",
      "        [-4,  3,  2,  1],\n",
      "        [-2,  3,  0, -2],\n",
      "        [ 1, -3,  2, -2]])\n",
      "\n",
      "--- 使用 where 处理后的 Tensor ---\n",
      "tensor([[2, 4, 3, 2],\n",
      "        [0, 3, 2, 1],\n",
      "        [0, 3, 0, 0],\n",
      "        [1, 0, 2, 0]])\n",
      "\n",
      "--- 使用布尔索引处理后的 Tensor ---\n",
      "tensor([[2, 4, 3, 2],\n",
      "        [0, 3, 2, 1],\n",
      "        [0, 3, 0, 0],\n",
      "        [1, 0, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(35)\n",
    "# 创建一个 4x4 的随机张量\n",
    "Z = torch.randint(-5, 5, (4, 4))\n",
    "\n",
    "# 使用 torch.where(condition, x, y)\n",
    "# 当条件为 True 时，取 x 的值；否则取 y 的值\n",
    "# 这里 y 我们用一个全零的标量 0 代替，它会自动广播\n",
    "result = torch.where(Z > 0, Z, 0)\n",
    "\n",
    "# 尝试使用布尔索引\n",
    "result_bool = torch.zeros_like(Z)\n",
    "result_bool[Z > 0] = Z[Z > 0] # 虽然布尔索引可以实现，但是不是原地操作\n",
    "\n",
    "print(\"--- 原始 Tensor Z ---\")\n",
    "print(Z)\n",
    "print(\"\\n--- 使用 where 处理后的 Tensor ---\")\n",
    "print(result)\n",
    "print(\"\\n--- 使用布尔索引处理后的 Tensor ---\")\n",
    "print(result_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 26. 内存布局：理解 contiguous (★★☆)\n",
    "任务: 创建一个 3x4 的张量 A，然后通过 transpose(0, 1) 将其变为 4x3。检查转置后的张量 A_t 的内存是否还是连续的 (is_contiguous())。尝试对 A_t 执行 .view(2, 6) 操作，观察是否会报错，并解释原因。最后，使用 .contiguous() 修复它，再成功地改变其形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始 Tensor A 是连续的吗? True\n",
      "转置后的 Tensor A_t 是连续的吗? False\n",
      "\n",
      "--- 直接对 A_t 使用 .view() 失败！---\n",
      "错误信息: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "\n",
      "--- A_t.contiguous() 是连续的吗? True ---\n",
      "--- 成功 view 后的 Tensor (2x6) ---\n",
      "tensor([[ 0,  4,  8,  1,  5,  9],\n",
      "        [ 2,  6, 10,  3,  7, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 3x4 张量\n",
    "A = torch.arange(12).reshape(3, 4)\n",
    "print(f\"原始 Tensor A 是连续的吗? {A.is_contiguous()}\")\n",
    "\n",
    "# 转置张量\n",
    "A_t = A.transpose(0, 1)\n",
    "print(f\"转置后的 Tensor A_t 是连续的吗? {A_t.is_contiguous()}\")\n",
    "\n",
    "# 尝试对非连续张量使用 .view()\n",
    "try:\n",
    "    A_t.view(2, 6)\n",
    "except RuntimeError as e:\n",
    "    print(\"\\n--- 直接对 A_t 使用 .view() 失败！---\")\n",
    "    print(f\"错误信息: {e}\")\n",
    "\n",
    "# 使用 .contiguous() 创建一个内存连续的副本，再进行 view\n",
    "A_contiguous = A_t.contiguous()\n",
    "print(f\"\\n--- A_t.contiguous() 是连续的吗? {A_contiguous.is_contiguous()} ---\")\n",
    "A_view = A_contiguous.view(2, 6)\n",
    "print(\"--- 成功 view 后的 Tensor (2x6) ---\")\n",
    "print(A_view)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 27. 高精度定向填充 (★★☆)\n",
    "任务：创建一个形状为 4×5 的全零张量 B。你需要按以下要求精确地在特定位置填入值：\n",
    "- 在第 0 行的第 2 列填入 11\n",
    "- 在第 1 行的第 0 列填入 22\n",
    "- 在第 3 行的第 4 列填入 33\n",
    "\n",
    "这个操作要求你能够根据给定的位置索引（行和列）高效地更新张量中的特定元素。\n",
    "\n",
    "提示：考虑如何通过索引列表同时定位并更新多个不同位置的值，尝试寻找一种比循环更高效的张量操作方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 方法一：直接索引赋值的结果 ---\n",
      "tensor([[ 0,  0, 11,  0,  0],\n",
      "        [22,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0, 33]])\n",
      "\n",
      "--- 方法二：使用 index_put_ 操作的结果 ---\n",
      "tensor([[ 0,  0, 11,  0,  0],\n",
      "        [22,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0, 33]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 4x5 的全零张量\n",
    "B = torch.zeros(4, 5, dtype=torch.int64)\n",
    "\n",
    "# 方法一：直接索引赋值\n",
    "B[0, 2] = 11  # 在第 0 行的第 2 列填入 11\n",
    "B[1, 0] = 22  # 在第 1 行的第 0 列填入 22\n",
    "B[3, 4] = 33  # 在第 3 行的第 4 列填入 33\n",
    "\n",
    "print(\"--- 方法一：直接索引赋值的结果 ---\")\n",
    "print(B)\n",
    "\n",
    "# 定义要填充的位置索引\n",
    "row_indices = torch.tensor([0, 1, 3])\n",
    "col_indices = torch.tensor([2, 0, 4])\n",
    "values = torch.tensor([11, 22, 33])\n",
    "\n",
    "# 方法二：使用 index_put_ 操作\n",
    "B_index_put = torch.zeros(4, 5, dtype=torch.int64)\n",
    "\n",
    "# 使用 index_put_ 方法一次性更新多个位置\n",
    "B_index_put.index_put_((row_indices, col_indices), values)\n",
    "\n",
    "print(\"\\n--- 方法二：使用 index_put_ 操作的结果 ---\")\n",
    "print(B_index_put)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 28. 综合应用：掩码填充 (★★☆)\n",
    "任务: 创建一个 5x5 的序列张量 C（值为0-24）。创建一个布尔掩码 mask，其中所有大于 3 的元素位置为 True，并将 C 中对应 mask 为 True 的位置的值都改为 -1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor C ---\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "\n",
      "--- 布尔掩码 (值为 True 的位置将被填充) ---\n",
      "tensor([[False, False, False, False,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True]])\n",
      "\n",
      "--- masked_fill_ 后的结果 ---\n",
      "tensor([[ 0,  1,  2,  3, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1]])\n",
      "\n",
      "--- 直接索引赋值的结果 ---\n",
      "tensor([[ 0,  1,  2,  3, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 5x5 张量\n",
    "C = torch.arange(25).reshape(5, 5)\n",
    "\n",
    "# 创建布尔掩码\n",
    "mask = (C > 3)\n",
    "\n",
    "# 使用 masked_fill_ 进行原地填充\n",
    "# 注意函数名结尾的下划线 `_` 表示这是个原地 (in-place) 操作\n",
    "C.masked_fill_(mask, -1)\n",
    "\n",
    "print(\"--- 原始 Tensor C ---\")\n",
    "print(torch.arange(25).reshape(5, 5))\n",
    "print(\"\\n--- 布尔掩码 (值为 True 的位置将被填充) ---\")\n",
    "print(mask)\n",
    "print(\"\\n--- masked_fill_ 后的结果 ---\")\n",
    "print(C)\n",
    "\n",
    "# 直接使用索引赋值\n",
    "C = torch.arange(25).reshape(5, 5)\n",
    "C[C > 3] = -1\n",
    "print(\"\\n--- 直接索引赋值的结果 ---\")\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 29. 扩展与平铺：使用 expand 和 repeat (★★☆)\n",
    "任务: 创建一个形状为 (3, 1) 的张量 D。分别使用 .expand() 和 .repeat() 将其扩展为一个 3x4 的张量。比较两种方法，思考并探索它们在内存中的区别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor D (3x1) ---\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "\n",
      "--- 使用 expand 后的 Tensor (3x4) ---\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n",
      "\n",
      "--- 使用 repeat 后的 Tensor (3x4) ---\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n",
      "\n",
      "expand 后的 storage 指针与原指针相同: True\n",
      "repeat 后的 storage 指针与原指针相同: False\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 (3, 1) 的张量\n",
    "D = torch.tensor([[1], [2], [3]])\n",
    "\n",
    "# 使用 .expand(-1,4)，-1 表示该维度的大小不改变\n",
    "# .expand() 不会分配新内存，只是创建了新的视图，更高效\n",
    "D_expanded = D.expand(-1, 4)\n",
    "\n",
    "# 使用 .repeat(1,4)，1表示该维度不变，4表示该维度重复4次\n",
    "# .repeat() 会复制数据，在内存中创建新的副本\n",
    "D_repeated = D.repeat(1, 4)\n",
    "\n",
    "print(\"--- 原始 Tensor D (3x1) ---\")\n",
    "print(D)\n",
    "print(\"\\n--- 使用 expand 后的 Tensor (3x4) ---\")\n",
    "print(D_expanded)\n",
    "print(\"\\n--- 使用 repeat 后的 Tensor (3x4) ---\")\n",
    "print(D_repeated)\n",
    "\n",
    "# 验证 expand 不分配新内存\n",
    "D_expanded_storage_ptr = D_expanded.untyped_storage().data_ptr()\n",
    "D_storage_ptr = D.untyped_storage().data_ptr()\n",
    "print(f\"\\nexpand 后的 storage 指针与原指针相同: {D_expanded_storage_ptr == D_storage_ptr}\")\n",
    "\n",
    "# 验证 repeat 分配了新内存\n",
    "D_repeated_storage_ptr = D_repeated.untyped_storage().data_ptr()\n",
    "print(f\"repeat 后的 storage 指针与原指针相同: {D_repeated_storage_ptr == D_storage_ptr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30. 综合应用：图像批次处理 (★★☆)\n",
    "任务: 假设你有一个批次的灰度图像数据，其形状为 (10, 1, 28, 28)，代表 10 张 28x28 的单通道图像。现在，你需要将其转换为 (10, 28, 28, 3)，模拟将灰度图转为 RGB 图（通过简单复制通道）。\n",
    "\n",
    "- 移除大小为 1 的通道维度。\n",
    "- 增加一个新的通道维度。\n",
    "- 将新的通道维度扩展为 3。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: squeeze(1) 后形状: torch.Size([10, 28, 28])\n",
      "Step 2: unsqueeze(-1) 后形状: torch.Size([10, 28, 28, 1])\n",
      "Step 3: expand 后的最终形状: torch.Size([10, 28, 28, 3])\n"
     ]
    }
   ],
   "source": [
    "# 模拟一个批次的图像数据 (N, C, H, W)\n",
    "batch_images = torch.randn(10, 1, 28, 28)\n",
    "\n",
    "# 1. 移除大小为 1 的通道维度 -> (10, 28, 28)\n",
    "squeezed_batch = batch_images.squeeze(1)\n",
    "print(f\"Step 1: squeeze(1) 后形状: {squeezed_batch.shape}\")\n",
    "\n",
    "# 2. 在末尾增加一个新的通道维度 -> (10, 28, 28, 1)\n",
    "unsqueezed_batch = squeezed_batch.unsqueeze(-1)\n",
    "print(f\"Step 2: unsqueeze(-1) 后形状: {unsqueezed_batch.shape}\")\n",
    "\n",
    "# 3. 使用 expand 将最后一个维度扩展为 3 -> (10, 28, 28, 3)\n",
    "rgb_batch = unsqueezed_batch.expand(-1, -1, -1, 3)\n",
    "print(f\"Step 3: expand 后的最终形状: {rgb_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31. 综合挑战：提取棋盘格点 (★★★)\n",
    "任务: 创建一个 8x8 的张量 E，代表一个棋盘，值为 0 到 63。你的任务是只提取出所有 \"白格\" 上的数字。假设左上角 (0, 0) 是白格，那么行索引和列索引之和为偶数的位置就是白格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始棋盘 (8x8) ---\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [16, 17, 18, 19, 20, 21, 22, 23],\n",
      "        [24, 25, 26, 27, 28, 29, 30, 31],\n",
      "        [32, 33, 34, 35, 36, 37, 38, 39],\n",
      "        [40, 41, 42, 43, 44, 45, 46, 47],\n",
      "        [48, 49, 50, 51, 52, 53, 54, 55],\n",
      "        [56, 57, 58, 59, 60, 61, 62, 63]])\n",
      "\n",
      "--- 白格掩码 ---\n",
      "tensor([[ True, False,  True, False,  True, False,  True, False],\n",
      "        [False,  True, False,  True, False,  True, False,  True],\n",
      "        [ True, False,  True, False,  True, False,  True, False],\n",
      "        [False,  True, False,  True, False,  True, False,  True],\n",
      "        [ True, False,  True, False,  True, False,  True, False],\n",
      "        [False,  True, False,  True, False,  True, False,  True],\n",
      "        [ True, False,  True, False,  True, False,  True, False],\n",
      "        [False,  True, False,  True, False,  True, False,  True]])\n",
      "\n",
      "--- 方法一提取出的所有白格元素 ---\n",
      "tensor([ 0,  2,  4,  6,  9, 11, 13, 15, 16, 18, 20, 22, 25, 27, 29, 31, 32, 34,\n",
      "        36, 38, 41, 43, 45, 47, 48, 50, 52, 54, 57, 59, 61, 63])\n",
      "共提取了 32 个元素\n",
      "--- 方法二计算得到的rows和cols ---\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [4, 4, 4, 4, 4, 4, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6],\n",
      "        [7, 7, 7, 7, 7, 7, 7, 7]]) tensor([[0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7]])\n",
      "\n",
      "--- 方法二提取出的所有白格元素 ---\n",
      "tensor([ 0,  2,  4,  6,  9, 11, 13, 15, 16, 18, 20, 22, 25, 27, 29, 31, 32, 34,\n",
      "        36, 38, 41, 43, 45, 47, 48, 50, 52, 54, 57, 59, 61, 63])\n",
      "共提取了 32 个元素\n"
     ]
    }
   ],
   "source": [
    "# --- 解法一 ---\n",
    "# 创建一个 8x8 的棋盘\n",
    "E = torch.arange(64).reshape(8, 8)\n",
    "\n",
    "# 创建行和列的索引网格\n",
    "rows = torch.arange(8).view(8, 1)\n",
    "cols = torch.arange(8).view(1, 8)\n",
    "\n",
    "# 计算每个位置的索引和（广播机制）\n",
    "index_sum = rows + cols\n",
    "\n",
    "# 创建布尔掩码，索引和为偶数的位置是 True\n",
    "mask = (index_sum % 2 == 0)\n",
    "\n",
    "# 使用布尔索引提取白格上的元素\n",
    "white_cells = E[mask]\n",
    "\n",
    "print(\"--- 原始棋盘 (8x8) ---\")\n",
    "print(E)\n",
    "print(\"\\n--- 白格掩码 ---\")\n",
    "print(mask)\n",
    "print(\"\\n--- 方法一提取出的所有白格元素 ---\")\n",
    "print(white_cells)\n",
    "print(f\"共提取了 {white_cells.numel()} 个元素\")\n",
    "\n",
    "\n",
    "# --- 解法二 ---\n",
    "rows, cols = torch.meshgrid(torch.arange(8), torch.arange(8), indexing='ij')\n",
    "white_cells = E[(rows + cols) % 2 == 0] # 无广播操作，因为rows和cols都是8x8的矩阵\n",
    "print(\"--- 方法二计算得到的rows和cols ---\")\n",
    "print(rows, cols)\n",
    "print(\"\\n--- 方法二提取出的所有白格元素 ---\")\n",
    "print(white_cells)\n",
    "print(f\"共提取了 {white_cells.numel()} 个元素\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32. 综合挑战：批量矩阵特定对角线提取 (★★★)\n",
    "任务: 假设你有一个形状为 (4, 5, 5) 的张量 F，代表一个批次的 4 个 5x5 矩阵。你需要提取出这 4 个矩阵的主对角线元素，最终得到一个形状为 (4, 5) 的张量。请思考如何高效完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始批次张量形状 ---\n",
      "torch.Size([4, 5, 5])\n",
      "\n",
      "--- 使用 torch.diagonal 提取的结果 (4, 5) ---\n",
      "tensor([[ 0,  6, 12, 18, 24],\n",
      "        [25, 31, 37, 43, 49],\n",
      "        [50, 56, 62, 68, 74],\n",
      "        [75, 81, 87, 93, 99]])\n",
      "\n",
      "--- 使用手动索引提取的结果 (4, 5) ---\n",
      "tensor([[ 0,  6, 12, 18, 24],\n",
      "        [25, 31, 37, 43, 49],\n",
      "        [50, 56, 62, 68, 74],\n",
      "        [75, 81, 87, 93, 99]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个批次的矩阵\n",
    "F = torch.arange(4 * 5 * 5).reshape(4, 5, 5)\n",
    "\n",
    "# 方法一：使用 gather\n",
    "# 我们需要一个索引张量，告诉 gather 去哪里取值\n",
    "# 对于第 k 个矩阵，我们要取 (k, 0, 0), (k, 1, 1), ..., (k, 4, 4)\n",
    "# 这很难用一次 gather 完成。\n",
    "\n",
    "\n",
    "# 方法二：使用 torch.diagonal(F, offset=0, dim1=1, dim2=2)\n",
    "# offset=0 表示主对角线，dim1和dim2构成了一个平面，函数在这个平面上取对角线\n",
    "# 这是最直接、最简洁的方法\n",
    "diagonals_direct = torch.diagonal(F, offset=0, dim1=1, dim2=2)\n",
    "\n",
    "\n",
    "# 方法三：手动构造索引 (更底层，有助于理解)\n",
    "# 创建一个范围 [0, 1, 2, 3, 4]\n",
    "indices = torch.arange(5)\n",
    "# F[:, indices, indices] 这种索引方式在 PyTorch 中可以直接使用\n",
    "diagonals_manual = F[:, indices, indices]\n",
    "\n",
    "print(\"--- 原始批次张量形状 ---\")\n",
    "print(F.shape)\n",
    "# print(\"\\n--- 使用 gather 提取的结果 (4, 5) ---\")\n",
    "# print(diagonals_gather)\n",
    "print(\"\\n--- 使用 torch.diagonal 提取的结果 (4, 5) ---\")\n",
    "print(diagonals_direct)\n",
    "print(\"\\n--- 使用手动索引提取的结果 (4, 5) ---\")\n",
    "print(diagonals_manual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33. 综合挑战：翻转序列 (★★☆)\n",
    "任务: 给定一个形状为 (5, 10) 的张量 G，代表 5 个长度为 10 的序列。请将每个序列独立地进行翻转，得到一个同样形状为 (5, 10) 的新张量，其中每一行都是原始行的逆序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这种写法在numpy中支持，但在PyTorch中不支持\n",
      "\n",
      "--- 原始序列批次 (5, 10) ---\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
      "        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]])\n",
      "\n",
      "--- 使用torch.flip()翻转每个序列后的结果 ---\n",
      "tensor([[ 9,  8,  7,  6,  5,  4,  3,  2,  1,  0],\n",
      "        [19, 18, 17, 16, 15, 14, 13, 12, 11, 10],\n",
      "        [29, 28, 27, 26, 25, 24, 23, 22, 21, 20],\n",
      "        [39, 38, 37, 36, 35, 34, 33, 32, 31, 30],\n",
      "        [49, 48, 47, 46, 45, 44, 43, 42, 41, 40]])\n",
      "\n",
      "--- 使用索引翻转每个序列后的结果 ---\n",
      "tensor([[ 9,  8,  7,  6,  5,  4,  3,  2,  1,  0],\n",
      "        [19, 18, 17, 16, 15, 14, 13, 12, 11, 10],\n",
      "        [29, 28, 27, 26, 25, 24, 23, 22, 21, 20],\n",
      "        [39, 38, 37, 36, 35, 34, 33, 32, 31, 30],\n",
      "        [49, 48, 47, 46, 45, 44, 43, 42, 41, 40]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个批次的序列\n",
    "G = torch.arange(50).reshape(5, 10)\n",
    "\n",
    "# --- 方法一 ---\n",
    "# 使用 `torch.flip()` 函数，指定要翻转的维度\n",
    "# dims控制反转的维度以及反转的顺序，[1]表示在第二个维度上反转\n",
    "G_flipped = torch.flip(G, dims=[1])\n",
    "\n",
    "# --- 方法二 ---\n",
    "# 使用索引反转每个序列\n",
    "G_flipped_index = G[:, torch.arange(G.size(1)-1, -1, -1)]\n",
    "\n",
    "# 也可以使用倒序列表作为索引下标，但是思路相同\n",
    "# index = [i for i in range(G.size(1)-1, -1, -1)]\n",
    "# G_flipped_index = G[:, index]\n",
    "\n",
    "# --- 方法三 ---\n",
    "# 使用切片反转每个序列\n",
    "# 语法 G[:, ::-1] 但在PyTorch中需要用专门的索引表示法\n",
    "try:\n",
    "    G_flipped_slice = G[:, ::-1]\n",
    "except:\n",
    "    print(\"这种写法在numpy中支持，但在PyTorch中不支持\\n\")\n",
    "\n",
    "print(\"--- 原始序列批次 (5, 10) ---\")\n",
    "print(G)\n",
    "print(\"\\n--- 使用torch.flip()翻转每个序列后的结果 ---\")\n",
    "print(G_flipped)\n",
    "print(\"\\n--- 使用索引翻转每个序列后的结果 ---\")\n",
    "print(G_flipped_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 34. 综合挑战：创建 One-Hot 编码 (★★★)\n",
    "任务: One-Hot 编码是分类任务中常用的数据预处理步骤。给定一个包含类别索引的一维张量 labels = torch.tensor([0, 2, 1, 4]) 和类别总数 num_classes = 5，请创建一个 4x5 的 One-Hot 编码张量。每一行对应一个标签，该行中标签索引的位置为 1，其余为 0。请尝试用 scatter_ 实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始标签 ---\n",
      "tensor([0, 2, 1, 4])\n",
      "\n",
      "--- 转换后的 One-Hot 编码张量 (4x5) ---\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 输入的标签和类别总数\n",
    "labels = torch.tensor([0, 2, 1, 4])\n",
    "num_classes = 5\n",
    "num_labels = labels.shape[0]\n",
    "\n",
    "# 1. 创建一个全零的目标张量 [4,5]\n",
    "one_hot = torch.zeros(num_labels, num_classes)\n",
    "\n",
    "# 2. 准备 scatter_ 需要的 index 张量\n",
    "# labels 需要是 (4, 1) 的形状，以指定每一行要修改的列索引\n",
    "index = labels.unsqueeze(1)\n",
    "\n",
    "# 3. 使用 scatter_ 填充\n",
    "# 在 dim=1 (列方向) 上操作\n",
    "# 对于 one_hot 的第 i 行，在 index[i] (也就是 labels[i]) 指定的列上，填入值 1\n",
    "one_hot.scatter_(dim=1, index=index, value=1.0)\n",
    "\n",
    "\n",
    "print(\"--- 原始标签 ---\")\n",
    "print(labels)\n",
    "print(\"\\n--- 转换后的 One-Hot 编码张量 (4x5) ---\")\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 35. 终极挑战：块交换 (★★★)\n",
    "任务: 创建一个 6x6 的张量 H。将其在两个维度上都均匀切分成 4 个 3x3 的块，然后将这 4 个块进行对角线交换（左上与右下交换，右上与左下交换）。\n",
    "\n",
    "原始布局: [[A, B], [C, D]]\n",
    "目标布局: [[D, C], [B, A]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 H (6x6) ---\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23],\n",
      "        [24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35]])\n",
      "\n",
      "--- 左上块 A ---\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 6,  7,  8],\n",
      "        [12, 13, 14]])\n",
      "--- 右上块 B ---\n",
      "tensor([[ 3,  4,  5],\n",
      "        [ 9, 10, 11],\n",
      "        [15, 16, 17]])\n",
      "--- 左下块 C ---\n",
      "tensor([[18, 19, 20],\n",
      "        [24, 25, 26],\n",
      "        [30, 31, 32]])\n",
      "--- 右下块 D ---\n",
      "tensor([[21, 22, 23],\n",
      "        [27, 28, 29],\n",
      "        [33, 34, 35]])\n",
      "\n",
      "--- 交换块后的最终结果 ---\n",
      "tensor([[21, 22, 23, 18, 19, 20],\n",
      "        [27, 28, 29, 24, 25, 26],\n",
      "        [33, 34, 35, 30, 31, 32],\n",
      "        [ 3,  4,  5,  0,  1,  2],\n",
      "        [ 9, 10, 11,  6,  7,  8],\n",
      "        [15, 16, 17, 12, 13, 14]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 6x6 张量\n",
    "H = torch.arange(36).reshape(6, 6)\n",
    "\n",
    "# 1. 将 H 分割成 4 个 3x3 的块\n",
    "# 先沿行分割\n",
    "H_top, H_bottom = torch.chunk(H, 2, dim=0)\n",
    "# 再对上下两部分分别沿列分割\n",
    "A, B = torch.chunk(H_top, 2, dim=1)\n",
    "C, D = torch.chunk(H_bottom, 2, dim=1)\n",
    "\n",
    "# 2. 按照新的布局重新拼接\n",
    "# 创建新的顶行 [D, C] 和底行 [B, A]\n",
    "new_top_row = torch.cat((D, C), dim=1)\n",
    "new_bottom_row = torch.cat((B, A), dim=1)\n",
    "\n",
    "# 将新的两行沿行方向拼接\n",
    "result = torch.cat((new_top_row, new_bottom_row), dim=0)\n",
    "\n",
    "print(\"--- 原始张量 H (6x6) ---\")\n",
    "print(H)\n",
    "print(\"\\n--- 左上块 A ---\")\n",
    "print(A)\n",
    "print(\"--- 右上块 B ---\")\n",
    "print(B)\n",
    "print(\"--- 左下块 C ---\")\n",
    "print(C)\n",
    "print(\"--- 右下块 D ---\")\n",
    "print(D)\n",
    "print(\"\\n--- 交换块后的最终结果 ---\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
