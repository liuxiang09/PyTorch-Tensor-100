{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模块一：Tensor 的创建与属性 ✨\n",
    "这部分将带您熟悉创建张量的各种方式，并了解如何查看它们的基本属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 导入 PyTorch (★☆☆)\n",
    "任务: 导入 torch 和 numpy 库，并打印各自的版本号，这是使用 PyTorch 的第一步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本: 2.5.1+cu121\n",
      "NumPy 版本: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# 导入 torch 和 numpy 库\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 打印导入成功信息和版本号\n",
    "print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "print(f\"NumPy 版本: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 从 Python 列表与 NumPy 数组创建 (★☆☆)\n",
    "任务: 将一个 Python 列表 [[1, 2], [3, 4]] 和一个 NumPy 数组 np.array([[5, 6], [7, 8]]) 分别转换为 Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 从列表创建的 Tensor ---\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "--- 从 NumPy 创建的 Tensor ---\n",
      "tensor([[5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# 定义一个 Python 列表\n",
    "data = [[1, 2], [3, 4]]\n",
    "# 创建一个 NumPy 数组\n",
    "np_arr = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# 从列表创建\n",
    "X = torch.tensor(data)\n",
    "# 从 NumPy 数组创建 (注意：会共享内存)\n",
    "Y = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"--- 从列表创建的 Tensor ---\")\n",
    "print(X)\n",
    "print(\"\\n--- 从 NumPy 创建的 Tensor ---\")\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 创建常量 Tensor (★☆☆)\n",
    "任务: 创建三个形状均为 (2, 3) 的张量：一个全零张量，一个全一张量，以及一个所有元素均为常数 7 的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 全零 Tensor ---\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "--- 全一 Tensor ---\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "--- 填充为 7 的 Tensor ---\n",
      "tensor([[7, 7, 7],\n",
      "        [7, 7, 7]])\n"
     ]
    }
   ],
   "source": [
    "# 定义形状\n",
    "shape = (2, 3)\n",
    "\n",
    "# 创建全零、全一、全为7的张量\n",
    "t_zeros = torch.zeros(shape)\n",
    "t_ones = torch.ones(shape)\n",
    "t_sevens = torch.full(shape, 7)\n",
    "\n",
    "print(\"--- 全零 Tensor ---\")\n",
    "print(t_zeros)\n",
    "print(\"\\n--- 全一 Tensor ---\")\n",
    "print(t_ones)\n",
    "print(\"\\n--- 填充为 7 的 Tensor ---\")\n",
    "print(t_sevens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 获取 Tensor 的核心属性 (★☆☆)\n",
    "任务: 对于给定的张量 X = torch.tensor([[1.0, 2.0], [3.0, 4.0]])，一次性打印出它的形状 (shape)、数据类型 (dtype) 和所在设备 (device)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tensor 的核心属性 ---\n",
      "形状 (Shape): torch.Size([2, 2])\n",
      "数据类型 (dtype): torch.float32\n",
      "所在设备 (device): cpu\n"
     ]
    }
   ],
   "source": [
    "# 创建一个示例张量\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# 获取并打印核心属性\n",
    "print(f\"--- Tensor 的核心属性 ---\")\n",
    "print(f\"形状 (Shape): {X.shape}\")\n",
    "print(f\"数据类型 (dtype): {X.dtype}\")\n",
    "print(f\"所在设备 (device): {X.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 创建指定数据类型的 Tensor (★☆☆)\n",
    "任务: 创建一个形状为 (2, 3)，数据类型为 torch.float16 (半精度浮点) 的全一 Tensor，并验证其数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 创建的 Tensor ---\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float16)\n",
      "\n",
      "--- 验证其数据类型 ---\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# 定义形状和目标数据类型\n",
    "shape = (2, 3)\n",
    "dtype = torch.float16\n",
    "\n",
    "# 在创建时通过 dtype 参数指定数据类型\n",
    "Y = torch.ones(shape, dtype=dtype)\n",
    "\n",
    "print(f\"--- 创建的 Tensor ---\")\n",
    "print(Y)\n",
    "print(f\"\\n--- 验证其数据类型 ---\")\n",
    "print(Y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 仿照其他 Tensor 创建新 Tensor (★☆☆)\n",
    "任务: 给定一个已存在的源张量 src，它的值为 [[1, 2, 3], [4, 5, 6]] 且类型为 float16，请创建一个与它属性（形状、类型、设备）都相同，但值为全零的新 Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 源 Tensor ---\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float16)\n",
      "属性: torch.Size([2, 3]), torch.float16, cpu\n",
      "\n",
      "--- 仿照创建的全零 Tensor ---\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float16)\n",
      "属性: torch.Size([2, 3]), torch.float16, cpu\n"
     ]
    }
   ],
   "source": [
    "# 定义一个源张量\n",
    "src = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float16)\n",
    "\n",
    "# 使用 _like 函数可以方便地复制属性\n",
    "Z = torch.zeros_like(src)\n",
    "\n",
    "print(\"--- 源 Tensor ---\")\n",
    "print(src)\n",
    "print(f\"属性: {src.shape}, {src.dtype}, {src.device}\")\n",
    "print(\"\\n--- 仿照创建的全零 Tensor ---\")\n",
    "print(Z)\n",
    "print(f\"属性: {Z.shape}, {Z.dtype}, {Z.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 创建不同分布的随机 Tensor (★☆☆)\n",
    "任务: 创建两个形状均为 (3, 3) 的随机 Tensor：X 的元素在 [0, 1) 区间均匀分布，Y 的元素服从标准正态分布（均值为0，方差为1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [0, 1) 均匀分布随机 Tensor ---\n",
      "tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009],\n",
      "        [0.2566, 0.7936, 0.9408]])\n",
      "\n",
      "--- 标准正态分布随机 Tensor ---\n",
      "tensor([[ 1.5231,  0.6647, -1.0324],\n",
      "        [-0.2770, -0.1671, -0.1079],\n",
      "        [-1.4285, -0.2810,  0.7489]])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以保证结果可复现\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 定义形状\n",
    "shape = (3, 3)\n",
    "\n",
    "# 创建不同分布的随机张量\n",
    "X = torch.rand(shape)  # 均匀分布\n",
    "Y = torch.randn(shape) # 标准正态分布\n",
    "\n",
    "print(f\"--- [0, 1) 均匀分布随机 Tensor ---\")\n",
    "print(X)\n",
    "print(f\"\\n--- 标准正态分布随机 Tensor ---\")\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. 创建序列 Tensor (★☆☆)\n",
    "任务: 创建两个序列 Tensor：X 是一个从 0 到 10（不含10）、步长为1的整数序列；Y 是一个从 0 到 1（包含1）、均匀划分成5个元素的浮点数序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- arange 创建的整数序列 ---\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "--- linspace 创建的等差序列 ---\n",
      "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# 使用 arange 创建整数序列 (不含结束点)\n",
    "X = torch.arange(0, 10)\n",
    "\n",
    "# 使用 linspace 创建等差序列 (包含结束点)\n",
    "# 参数: start, end, steps\n",
    "Y = torch.linspace(0, 1, 5)\n",
    "\n",
    "print(\"--- arange 创建的整数序列 ---\")\n",
    "print(X)\n",
    "print(\"\\n--- linspace 创建的等差序列 ---\")\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. 在指定设备上创建 Tensor (★☆☆)\n",
    "任务: 检查您的环境中 CUDA (GPU) 是否可用，如果可用，则在第一个 GPU (cuda:0) 上创建一个 2x2 的全一张量；否则，在 CPU 上创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 创建的 Tensor ---\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], device='cuda:0')\n",
      "它所在的设备是: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 检查 CUDA 是否可用\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 使用 device 参数在指定设备上创建张量\n",
    "Z = torch.ones(2, 2, device=device)\n",
    "\n",
    "print(f\"\\n--- 创建的 Tensor ---\")\n",
    "print(Z)\n",
    "print(f\"它所在的设备是: {Z.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模块二：索引、切片与形状变换 🔪\n",
    "掌握了如何创建 Tensor 后，下一步是学习如何灵活地访问和重塑它们。这是数据预处理和特征工程中的核心技能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 基础索引：访问特定元素 (★☆☆)\n",
    "任务: 创建一个 3x3 的序列张量 X，其值为 0 到 8。然后，访问并打印出位于第 2 行、第 1 列的元素（注意索引从0开始）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "\n",
      "--- 第2行、第1列的元素是 ---\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 3x3 的张量\n",
    "X = torch.arange(9).reshape(3, 3)\n",
    "\n",
    "# 访问第 2 行 (索引为1), 第 1 列 (索引为0) 的元素\n",
    "element = X[1, 0]\n",
    "\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(X)\n",
    "print(f\"\\n--- 第2行、第1列的元素是 ---\")\n",
    "print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. 基础切片：提取整行与整列 (★☆☆)\n",
    "任务: 对于一个 4x4 的序列张量 Y（值为0-15），提取并打印出它的第 3 整行和第 4 整列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "\n",
      "--- 第 3 行 ---\n",
      "tensor([ 8,  9, 10, 11])\n",
      "\n",
      "--- 第 4 列 ---\n",
      "tensor([ 3,  7, 11, 15])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 4x4 的张量\n",
    "Y = torch.arange(16).reshape(4, 4)\n",
    "\n",
    "# 提取第 3 行 (索引为2)\n",
    "third_row = Y[2, :] # 或者 Y[2]\n",
    "\n",
    "# 提取第 4 列 (索引为3)\n",
    "fourth_col = Y[:, 3]\n",
    "\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(Y)\n",
    "print(\"\\n--- 第 3 行 ---\")\n",
    "print(third_row)\n",
    "print(\"\\n--- 第 4 列 ---\")\n",
    "print(fourth_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. 进阶切片：提取子矩阵 (★☆☆)\n",
    "任务: 对于一个 5x5 的序列张量 Z（值为0-24），提取出由第3、4行和第2、3、4列共同构成的 2x3 子矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "\n",
      "--- 提取的 2x3 子矩阵 ---\n",
      "tensor([[11, 12, 13],\n",
      "        [16, 17, 18]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 5x5 的张量\n",
    "Z = torch.arange(25).reshape(5, 5)\n",
    "\n",
    "# 提取子矩阵：行索引为 2, 3；列索引为 1, 2, 3\n",
    "sub_matrix = Z[2:4, 1:4]\n",
    "\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(Z)\n",
    "print(\"\\n--- 提取的 2x3 子矩阵 ---\")\n",
    "print(sub_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. 布尔索引：筛选满足条件的元素 (★☆☆)\n",
    "任务: 创建一个 4x4 的随机整数张量 X（值在0-9之间），筛选出所有大于5的元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([[7, 5, 2, 7],\n",
      "        [2, 5, 7, 2],\n",
      "        [1, 5, 6, 3],\n",
      "        [1, 0, 6, 3]])\n",
      "\n",
      "--- 大于 5 的元素 ---\n",
      "tensor([7, 7, 7, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以保证结果可复现\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# 创建一个 4x4 的随机整数张量\n",
    "X = torch.randint(0, 10, (4, 4))\n",
    "\n",
    "# 创建布尔掩码 (Mask)\n",
    "mask = X > 5\n",
    "\n",
    "# 使用掩码进行索引，筛选出符合条件的元素\n",
    "filtered_elements = X[mask]\n",
    "\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(X)\n",
    "print(\"\\n--- 大于 5 的元素 ---\")\n",
    "print(filtered_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. 使用布尔索引进行原地修改 (★☆☆)\n",
    "任务: 创建一个 3x4 的标准正态分布随机张量 Y，然后将其中所有小于0的元素都原地修改为0（这类似于ReLU激活函数的操作）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([[-1.2061,  0.0617,  1.1632, -1.5008],\n",
      "        [-1.5944, -0.0187, -2.1325, -0.5270],\n",
      "        [-0.1021,  0.0099, -0.4454, -1.4976]])\n",
      "\n",
      "--- 修改后的 Tensor ---\n",
      "tensor([[0.0000, 0.0617, 1.1632, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0099, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(20)\n",
    "\n",
    "# 创建一个 3x4 的随机张量\n",
    "Y = torch.randn(3, 4)\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(Y)\n",
    "\n",
    "# 使用布尔索引找到小于0的元素，并原地赋值为0\n",
    "Y[Y < 0] = 0\n",
    "\n",
    "print(\"\\n--- 修改后的 Tensor ---\")\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. 改变形状 (★☆☆)\n",
    "任务: 创建一个值为 0-11 的一维张量 Z，然后将其形状变为 3x4。请分别使用两种不同的方法实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor ---\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "\n",
      "--- 使用 .view() 的结果 ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "--- 使用 .reshape() 的结果 ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个一维张量\n",
    "Z = torch.arange(12)\n",
    "\n",
    "# 使用 .view() 改变形状\n",
    "# .view() 要求原始张量的内存是连续的\n",
    "Z_view = Z.view(3, 4)\n",
    "\n",
    "# 使用 .reshape() 改变形状\n",
    "# .reshape() 更灵活，如果内存不连续，它会先创建副本再改变形状\n",
    "Z_reshape = Z.reshape(3, 4)\n",
    "\n",
    "print(\"--- 原始 Tensor ---\")\n",
    "print(Z)\n",
    "print(\"\\n--- 使用 .view() 的结果 ---\")\n",
    "print(Z_view)\n",
    "print(\"\\n--- 使用 .reshape() 的结果 ---\")\n",
    "print(Z_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. 增加维度 (★☆☆)\n",
    "任务: 创建一个形状为 (3, 4) 的张量 X。在第1个维度（dim=0）和第3个维度（dim=2）上增加一个新维度，使其最终形状变为 (1, 3, 1, 4)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor (shape: torch.Size([3, 4])) ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "--- 在 dim=0 unsqueeze 后 (shape: torch.Size([1, 3, 4])) ---\n",
      "--- 在 dim=2 unsqueeze 后 (shape: torch.Size([1, 3, 1, 4])) ---\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 3x4 的张量\n",
    "X = torch.arange(12).reshape(3, 4)\n",
    "print(f\"--- 原始 Tensor (shape: {X.shape}) ---\")\n",
    "print(X)\n",
    "\n",
    "# 在第 1 个维度 (dim=0) 增加维度\n",
    "X_unsqueezed_1 = X.unsqueeze(0)\n",
    "print(f\"\\n--- 在 dim=0 unsqueeze 后 (shape: {X_unsqueezed_1.shape}) ---\")\n",
    "\n",
    "# 在第 3 个维度 (dim=2) 增加维度\n",
    "X_unsqueezed_2 = X_unsqueezed_1.unsqueeze(2)\n",
    "print(f\"--- 在 dim=2 unsqueeze 后 (shape: {X_unsqueezed_2.shape}) ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. 压缩维度 (★☆☆)\n",
    "任务: 创建一个形状为 (1, 3, 1, 2) 的随机张量 Y，移除所有大小为1的维度，使其最终形状变为 (3, 2)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor (shape: torch.Size([1, 3, 1, 2])) ---\n",
      "tensor([[[[0.4489, 0.2113]],\n",
      "\n",
      "         [[0.6839, 0.7478]],\n",
      "\n",
      "         [[0.4627, 0.7742]]]])\n",
      "\n",
      "--- squeeze 后的 Tensor (shape: torch.Size([3, 2])) ---\n",
      "tensor([[0.4489, 0.2113],\n",
      "        [0.6839, 0.7478],\n",
      "        [0.4627, 0.7742]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个包含冗余维度的张量\n",
    "Y = torch.rand(1, 3, 1, 2)\n",
    "\n",
    "# 使用 .squeeze() 移除所有大小为1的维度\n",
    "Y_squeezed = Y.squeeze()\n",
    "\n",
    "print(f\"--- 原始 Tensor (shape: {Y.shape}) ---\")\n",
    "print(Y)\n",
    "print(f\"\\n--- squeeze 后的 Tensor (shape: {Y_squeezed.shape}) ---\")\n",
    "print(Y_squeezed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. 交换维度 (★☆☆)\n",
    "任务: 在深度学习中，图像张量通常以 (C, H, W)（通道, 高, 宽）格式存储。请创建一个形状为 (3, 224, 224) 的模拟图像张量 Z，并将其维度转换为 (H, W, C)，以方便图像显示，可以尝试多种方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor 形状 (C, H, W) ---\n",
      "torch.Size([3, 224, 224])\n",
      "\n",
      "--- permute 后的 Tensor 形状 (H, W, C) ---\n",
      "torch.Size([224, 224, 3])\n",
      "\n",
      "--- transpose 后的 Tensor 形状 (H, W, C) ---\n",
      "torch.Size([224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个模拟图像张量 (通道, 高, 宽)\n",
    "C, H, W = 3, 224, 224\n",
    "Z = torch.randn(C, H, W)\n",
    "\n",
    "# 使用 .permute() 交换维度\n",
    "# 将 (0, 1, 2) -> (1, 2, 0)\n",
    "Z_permuted = Z.permute(1, 2, 0)\n",
    "\n",
    "# 使用 .transpose() 交换维度\n",
    "Z_transpose = Z.transpose(0, 1).transpose(1, 2)\n",
    "\n",
    "\n",
    "print(f\"--- 原始 Tensor 形状 (C, H, W) ---\")\n",
    "print(Z.shape)\n",
    "print(f\"\\n--- permute 后的 Tensor 形状 (H, W, C) ---\")\n",
    "print(Z_permuted.shape)\n",
    "print(f\"\\n--- transpose 后的 Tensor 形状 (H, W, C) ---\")\n",
    "print(Z_transpose.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. 沿现有维度拼接张量 (★☆☆)\n",
    "任务: 创建两个形状均为 (2, 3) 的张量 X ∈ [0,6) 和 Y ∈ [6,12)。将它们分别沿维度0（行方向）和维度1（列方向）进行拼接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor X ---\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "--- 原始 Tensor Y ---\n",
      "tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "\n",
      "--- 沿 dim=0 拼接 (结果形状: 4x3) ---\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "\n",
      "--- 沿 dim=1 拼接 (结果形状: 2x6) ---\n",
      "tensor([[ 0,  1,  2,  6,  7,  8],\n",
      "        [ 3,  4,  5,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 创建两个 2x3 的张量\n",
    "X = torch.arange(6).reshape(2, 3)\n",
    "Y = torch.arange(6, 12).reshape(2, 3)\n",
    "\n",
    "# 沿维度0 (行) 拼接\n",
    "cat_dim0 = torch.cat((X, Y), dim=0)\n",
    "\n",
    "# 沿维度1 (列) 拼接\n",
    "cat_dim1 = torch.cat((X, Y), dim=1)\n",
    "\n",
    "print(\"--- 原始 Tensor X ---\")\n",
    "print(X)\n",
    "print(\"\\n--- 原始 Tensor Y ---\")\n",
    "print(Y)\n",
    "print(\"\\n--- 沿 dim=0 拼接 (结果形状: 4x3) ---\")\n",
    "print(cat_dim0)\n",
    "print(\"\\n--- 沿 dim=1 拼接 (结果形状: 2x6) ---\")\n",
    "print(cat_dim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20. 沿新维度堆叠张量 (★☆☆)\n",
    "任务: 创建两个形状均为 (2, 3) 的张量 X 和 Y。将它们堆叠起来，创建一个新的维度，使结果张量的形状变为 (2, 2, 3)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor X (shape: 2x3) ---\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n",
      "--- 原始 Tensor Y (shape: 2x3) ---\n",
      "tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "\n",
      "--- 堆叠后的 Tensor (结果形状: 2x2x3) ---\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "堆叠后形状: torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 重新创建两个 2x3 的张量\n",
    "X = torch.arange(6).reshape(2, 3)\n",
    "Y = torch.arange(6, 12).reshape(2, 3)\n",
    "\n",
    "# 沿一个新维度 (dim=0) 进行堆叠\n",
    "stacked_tensor = torch.stack((X, Y), dim=0)\n",
    "\n",
    "print(\"--- 原始 Tensor X (shape: 2x3) ---\")\n",
    "print(X)\n",
    "print(\"\\n--- 原始 Tensor Y (shape: 2x3) ---\")\n",
    "print(Y)\n",
    "print(\"\\n--- 堆叠后的 Tensor (结果形状: 2x2x3) ---\")\n",
    "print(stacked_tensor)\n",
    "print(f\"堆叠后形状: {stacked_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21. 分割张量：精确控制与便捷分割 (★★☆)\n",
    "任务: 对一个7x4的张量Z，将其沿行（dim=0）均匀分割成2块（可以尝试两种方法），再将第一个块其沿行（dim=0）分割成不等大小的块[1,3]，PyTorch会自动处理不能整除的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 用于分割的原始 Tensor (7x4) ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19],\n",
      "        [20, 21, 22, 23],\n",
      "        [24, 25, 26, 27]])\n",
      "--- chunk 分割成的2个块 ---\n",
      "(tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]]), tensor([[16, 17, 18, 19],\n",
      "        [20, 21, 22, 23],\n",
      "        [24, 25, 26, 27]]))\n",
      "--- split 分割成的2个块 ---\n",
      "(tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]]), tensor([[16, 17, 18, 19],\n",
      "        [20, 21, 22, 23],\n",
      "        [24, 25, 26, 27]]))\n",
      "--- split 分割成不等大小的块 (分别为1, 3行) ---\n",
      "(tensor([[0, 1, 2, 3]]), tensor([[ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]]))\n"
     ]
    }
   ],
   "source": [
    "Z = torch.arange(28).reshape(7, 4)\n",
    "print(\"--- 用于分割的原始 Tensor (7x4) ---\")\n",
    "print(Z)\n",
    "\n",
    "# 将张量沿 dim=0 分割成大小分别为2块\n",
    "chunks = torch.chunk(Z, 2, dim=0)\n",
    "print(\"--- chunk 分割成的2个块 ---\")\n",
    "print(chunks)\n",
    "\n",
    "# 将张量沿 dim=0 分割成大小分别为2块(这里的4指的是每块大小为4)\n",
    "splits = torch.split(Z, 4, dim=0)\n",
    "print(\"--- split 分割成的2个块 ---\")\n",
    "print(splits)\n",
    "\n",
    "# 将第一个块沿 dim=0 分割成不等大小的块\n",
    "unequal_chunks = torch.split(chunks[0], [1, 3], dim=0)\n",
    "print(\"--- split 分割成不等大小的块 (分别为1, 3行) ---\")\n",
    "print(unequal_chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22. 综合运用：重塑与拼接 (★★☆)\n",
    "任务: 假设你有一个批次的数据 (Batch, Features)，形状为 (4, 10)。你需要将其分成两组，每组2个样本，分别进行不同的处理（这里可以用乘以不同常数模拟×2 or ×3），然后再将处理后的结果合并起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始批次数据 (4x10) ---\n",
      "torch.Size([4, 10])\n",
      "tensor([[7, 5, 2, 7, 2, 5, 7, 2, 1, 5],\n",
      "        [6, 3, 1, 0, 6, 3, 4, 0, 6, 2],\n",
      "        [8, 9, 2, 0, 9, 9, 4, 4, 9, 4],\n",
      "        [4, 5, 4, 0, 8, 9, 3, 0, 9, 3]])\n",
      "\n",
      "--- 分割后的两组 (均为 2x10) ---\n",
      "组1形状: torch.Size([2, 10]), 组2形状: torch.Size([2, 10])\n",
      "tensor([[7, 5, 2, 7, 2, 5, 7, 2, 1, 5],\n",
      "        [6, 3, 1, 0, 6, 3, 4, 0, 6, 2]])\n",
      "tensor([[8, 9, 2, 0, 9, 9, 4, 4, 9, 4],\n",
      "        [4, 5, 4, 0, 8, 9, 3, 0, 9, 3]])\n",
      "\n",
      "--- 重新拼接后的最终批次 (4x10) ---\n",
      "torch.Size([4, 10])\n",
      "tensor([[14, 10,  4, 14,  4, 10, 14,  4,  2, 10],\n",
      "        [12,  6,  2,  0, 12,  6,  8,  0, 12,  4],\n",
      "        [24, 27,  6,  0, 27, 27, 12, 12, 27, 12],\n",
      "        [12, 15, 12,  0, 24, 27,  9,  0, 27,  9]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "# 创建一个模拟的批次数据\n",
    "batch_data = torch.randint(0, 10, (4, 10))\n",
    "\n",
    "# 1. 将数据分割成两组\n",
    "group1, group2 = torch.chunk(batch_data, 2, dim=0)\n",
    "\n",
    "# 2. 模拟对两组数据进行不同的处理\n",
    "processed_group1 = group1 * 2\n",
    "processed_group2 = group2 * 3\n",
    "\n",
    "# 3. 将处理后的结果重新拼接成一个批次\n",
    "final_batch = torch.cat((processed_group1, processed_group2), dim=0)\n",
    "\n",
    "print(\"--- 原始批次数据 (4x10) ---\")\n",
    "print(batch_data.shape)\n",
    "print(batch_data)\n",
    "print(\"\\n--- 分割后的两组 (均为 2x10) ---\")\n",
    "print(f\"组1形状: {group1.shape}, 组2形状: {group2.shape}\")\n",
    "print(group1)\n",
    "print(group2)\n",
    "print(\"\\n--- 重新拼接后的最终批次 (4x10) ---\")\n",
    "print(final_batch.shape)\n",
    "print(final_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23. 高级索引：按指定索引筛选 (★★☆)\n",
    "任务: 创建一个 5x4 的张量 X（值为0-19）。现在，你有一个包含行索引的 1D 张量tensor([0, 3, 1, 3])。请从 X 中提取出这些索引对应的行，并组成新的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor (5x4) ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19]])\n",
      "\n",
      "--- 指定的行索引 ---\n",
      "tensor([0, 3, 1, 3])\n",
      "\n",
      "--- index_select 提取的结果 ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [12, 13, 14, 15],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [12, 13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 5x4 的张量\n",
    "X = torch.arange(20).reshape(5, 4)\n",
    "# 定义要提取的行索引\n",
    "indices = torch.tensor([0, 3, 1, 3])\n",
    "\n",
    "# 使用 index_select 沿维度 0 (行) 提取\n",
    "selected_rows = torch.index_select(X, dim=0, index=indices)\n",
    "\n",
    "print(\"--- 原始 Tensor (5x4) ---\")\n",
    "print(X)\n",
    "print(\"\\n--- 指定的行索引 ---\")\n",
    "print(indices)\n",
    "print(\"\\n--- index_select 提取的结果 ---\")\n",
    "print(selected_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24. 高级索引：按指定索引收集 (★★★)\n",
    "任务: 给定一个 3x5 的随机int张量 Y，以及一个 3x2 的索引张量 indices。我们需要从 Y 中有选择地提取元素，具体规则是：indices 的每一行包含2个数字，指定从 Y 对应行中应该选择哪些列（例如，如果 indices[0] = [4, 1]，则从 Y 的第 0 行中选择第 4 列和第 1 列的元素），最终结果应该是一个形状为 3x2 的新张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor Y (3x5) ---\n",
      "tensor([[67, 77, 77, 13, 66],\n",
      "        [34, 89, 72, 27, 37],\n",
      "        [45, 76, 61, 45, 59]])\n",
      "\n",
      "--- 要收集的列索引 (3x2) ---\n",
      "tensor([[4, 1],\n",
      "        [0, 2],\n",
      "        [3, 3]])\n",
      "\n",
      "--- 按索引选择的结果 (3x2) ---\n",
      "tensor([[66, 77],\n",
      "        [34, 72],\n",
      "        [45, 45]])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以保证结果可复现\n",
    "torch.manual_seed(30)\n",
    "\n",
    "# 创建一个 3x5 的随机张量\n",
    "Y = torch.randint(10, 100, (3, 5))\n",
    "# 第0行收集第4、1列；第1行收集第0、2列；第2行收集第3、3列\n",
    "indices = torch.tensor([[4, 1], [0, 2], [3, 3]])\n",
    "\n",
    "# 按照索引从原始张量中提取特定元素\n",
    "# 输出形状与索引张量的形状相同\n",
    "gathered_elements = torch.gather(Y, dim=1, index=indices)\n",
    "\n",
    "print(\"--- 原始 Tensor Y (3x5) ---\")\n",
    "print(Y)\n",
    "print(\"\\n--- 要收集的列索引 (3x2) ---\")\n",
    "print(indices)\n",
    "print(\"\\n--- 按索引选择的结果 (3x2) ---\")\n",
    "print(gathered_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25. 条件元素替换与形状保持(★★☆)\n",
    "任务: 创建一个 4x4 的随机整数张量 Z (值在 -5 到 5 之间)。对 Z 中的每个元素应用条件判断，如果元素值大于 0，则保留原始值；如果元素值小于等于 0，则将其替换为 0，输出结果应当保持与输入张量完全相同的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor Z ---\n",
      "tensor([[ 2,  4,  3,  2],\n",
      "        [-4,  3,  2,  1],\n",
      "        [-2,  3,  0, -2],\n",
      "        [ 1, -3,  2, -2]])\n",
      "\n",
      "--- 使用 where 处理后的 Tensor ---\n",
      "tensor([[2, 4, 3, 2],\n",
      "        [0, 3, 2, 1],\n",
      "        [0, 3, 0, 0],\n",
      "        [1, 0, 2, 0]])\n",
      "\n",
      "--- 使用布尔索引处理后的 Tensor ---\n",
      "tensor([[2, 4, 3, 2],\n",
      "        [0, 3, 2, 1],\n",
      "        [0, 3, 0, 0],\n",
      "        [1, 0, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(35)\n",
    "# 创建一个 4x4 的随机张量\n",
    "Z = torch.randint(-5, 5, (4, 4))\n",
    "\n",
    "# 使用 torch.where(condition, x, y)\n",
    "# 当条件为 True 时，取 x 的值；否则取 y 的值\n",
    "# 这里 y 我们用一个全零的标量 0 代替，它会自动广播\n",
    "result = torch.where(Z > 0, Z, 0)\n",
    "\n",
    "# 尝试使用布尔索引\n",
    "result_bool = torch.zeros_like(Z)\n",
    "result_bool[Z > 0] = Z[Z > 0] # 虽然布尔索引可以实现，但是不是原地操作\n",
    "\n",
    "print(\"--- 原始 Tensor Z ---\")\n",
    "print(Z)\n",
    "print(\"\\n--- 使用 where 处理后的 Tensor ---\")\n",
    "print(result)\n",
    "print(\"\\n--- 使用布尔索引处理后的 Tensor ---\")\n",
    "print(result_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 26. 内存布局：理解 contiguous (★★☆)\n",
    "任务: 创建一个 3x4 的张量 A，然后通过 transpose(0, 1) 将其变为 4x3。检查转置后的张量 A_t 的内存是否还是连续的 (is_contiguous())。尝试对 A_t 执行 .view(2, 6) 操作，观察是否会报错，并解释原因。最后，使用 .contiguous() 修复它，再成功地改变其形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始 Tensor A 是连续的吗? True\n",
      "转置后的 Tensor A_t 是连续的吗? False\n",
      "\n",
      "--- 直接对 A_t 使用 .view() 失败！---\n",
      "错误信息: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "\n",
      "--- A_t.contiguous() 是连续的吗? True ---\n",
      "--- 成功 view 后的 Tensor (2x6) ---\n",
      "tensor([[ 0,  4,  8,  1,  5,  9],\n",
      "        [ 2,  6, 10,  3,  7, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 3x4 张量\n",
    "A = torch.arange(12).reshape(3, 4)\n",
    "print(f\"原始 Tensor A 是连续的吗? {A.is_contiguous()}\")\n",
    "\n",
    "# 转置张量\n",
    "A_t = A.transpose(0, 1)\n",
    "print(f\"转置后的 Tensor A_t 是连续的吗? {A_t.is_contiguous()}\")\n",
    "\n",
    "# 尝试对非连续张量使用 .view()\n",
    "try:\n",
    "    A_t.view(2, 6)\n",
    "except RuntimeError as e:\n",
    "    print(\"\\n--- 直接对 A_t 使用 .view() 失败！---\")\n",
    "    print(f\"错误信息: {e}\")\n",
    "\n",
    "# 使用 .contiguous() 创建一个内存连续的副本，再进行 view\n",
    "A_contiguous = A_t.contiguous()\n",
    "print(f\"\\n--- A_t.contiguous() 是连续的吗? {A_contiguous.is_contiguous()} ---\")\n",
    "A_view = A_contiguous.view(2, 6)\n",
    "print(\"--- 成功 view 后的 Tensor (2x6) ---\")\n",
    "print(A_view)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 27. 高精度定向填充 (★★☆)\n",
    "任务：创建一个形状为 4×5 的全零张量 B。你需要按以下要求精确地在特定位置填入值：\n",
    "- 在第 0 行的第 2 列填入 11\n",
    "- 在第 1 行的第 0 列填入 22\n",
    "- 在第 3 行的第 4 列填入 33\n",
    "\n",
    "这个操作要求你能够根据给定的位置索引（行和列）高效地更新张量中的特定元素。\n",
    "\n",
    "提示：考虑如何通过索引列表同时定位并更新多个不同位置的值，尝试寻找一种比循环更高效的张量操作方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 方法一：直接索引赋值的结果 ---\n",
      "tensor([[ 0,  0, 11,  0,  0],\n",
      "        [22,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0, 33]])\n",
      "\n",
      "--- 方法二：使用 index_put_ 操作的结果 ---\n",
      "tensor([[ 0,  0, 11,  0,  0],\n",
      "        [22,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0, 33]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 4x5 的全零张量\n",
    "B = torch.zeros(4, 5, dtype=torch.int64)\n",
    "\n",
    "# 方法一：直接索引赋值\n",
    "B[0, 2] = 11  # 在第 0 行的第 2 列填入 11\n",
    "B[1, 0] = 22  # 在第 1 行的第 0 列填入 22\n",
    "B[3, 4] = 33  # 在第 3 行的第 4 列填入 33\n",
    "\n",
    "print(\"--- 方法一：直接索引赋值的结果 ---\")\n",
    "print(B)\n",
    "\n",
    "# 定义要填充的位置索引\n",
    "row_indices = torch.tensor([0, 1, 3])\n",
    "col_indices = torch.tensor([2, 0, 4])\n",
    "values = torch.tensor([11, 22, 33])\n",
    "\n",
    "# 方法二：使用 index_put_ 操作\n",
    "B_index_put = torch.zeros(4, 5, dtype=torch.int64)\n",
    "\n",
    "# 使用 index_put_ 方法一次性更新多个位置\n",
    "B_index_put.index_put_((row_indices, col_indices), values)\n",
    "\n",
    "print(\"\\n--- 方法二：使用 index_put_ 操作的结果 ---\")\n",
    "print(B_index_put)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 28. 综合应用：掩码填充 (★★☆)\n",
    "任务: 创建一个 5x5 的序列张量 C（值为0-24）。创建一个布尔掩码 mask，其中所有大于 3 的元素位置为 True，并将 C 中对应 mask 为 True 的位置的值都改为 -1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor C ---\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "\n",
      "--- 布尔掩码 (值为 True 的位置将被填充) ---\n",
      "tensor([[False, False, False, False,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True]])\n",
      "\n",
      "--- masked_fill_ 后的结果 ---\n",
      "tensor([[ 0,  1,  2,  3, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1]])\n",
      "\n",
      "--- 直接索引赋值的结果 ---\n",
      "tensor([[ 0,  1,  2,  3, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [-1, -1, -1, -1, -1]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 5x5 张量\n",
    "C = torch.arange(25).reshape(5, 5)\n",
    "\n",
    "# 创建布尔掩码\n",
    "mask = (C > 3)\n",
    "\n",
    "# 使用 masked_fill_ 进行原地填充\n",
    "# 注意函数名结尾的下划线 `_` 表示这是个原地 (in-place) 操作\n",
    "C.masked_fill_(mask, -1)\n",
    "\n",
    "print(\"--- 原始 Tensor C ---\")\n",
    "print(torch.arange(25).reshape(5, 5))\n",
    "print(\"\\n--- 布尔掩码 (值为 True 的位置将被填充) ---\")\n",
    "print(mask)\n",
    "print(\"\\n--- masked_fill_ 后的结果 ---\")\n",
    "print(C)\n",
    "\n",
    "# 直接使用索引赋值\n",
    "C = torch.arange(25).reshape(5, 5)\n",
    "C[C > 3] = -1\n",
    "print(\"\\n--- 直接索引赋值的结果 ---\")\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 29. 扩展与平铺：使用 expand 和 repeat (★★☆)\n",
    "任务: 创建一个形状为 (3, 1) 的张量 D。分别使用 .expand() 和 .repeat() 将其扩展为一个 3x4 的张量。比较两种方法，思考并探索它们在内存中的区别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始 Tensor D (3x1) ---\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "\n",
      "--- 使用 expand 后的 Tensor (3x4) ---\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n",
      "\n",
      "--- 使用 repeat 后的 Tensor (3x4) ---\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n",
      "\n",
      "expand 后的 storage 指针与原指针相同: True\n",
      "repeat 后的 storage 指针与原指针相同: False\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 (3, 1) 的张量\n",
    "D = torch.tensor([[1], [2], [3]])\n",
    "\n",
    "# 使用 .expand(-1,4)，-1 表示该维度的大小不改变\n",
    "# .expand() 不会分配新内存，只是创建了新的视图，更高效\n",
    "D_expanded = D.expand(-1, 4)\n",
    "\n",
    "# 使用 .repeat(1,4)，1表示该维度不变，4表示该维度重复4次\n",
    "# .repeat() 会复制数据，在内存中创建新的副本\n",
    "D_repeated = D.repeat(1, 4)\n",
    "\n",
    "print(\"--- 原始 Tensor D (3x1) ---\")\n",
    "print(D)\n",
    "print(\"\\n--- 使用 expand 后的 Tensor (3x4) ---\")\n",
    "print(D_expanded)\n",
    "print(\"\\n--- 使用 repeat 后的 Tensor (3x4) ---\")\n",
    "print(D_repeated)\n",
    "\n",
    "# 验证 expand 不分配新内存\n",
    "D_expanded_storage_ptr = D_expanded.untyped_storage().data_ptr()\n",
    "D_storage_ptr = D.untyped_storage().data_ptr()\n",
    "print(f\"\\nexpand 后的 storage 指针与原指针相同: {D_expanded_storage_ptr == D_storage_ptr}\")\n",
    "\n",
    "# 验证 repeat 分配了新内存\n",
    "D_repeated_storage_ptr = D_repeated.untyped_storage().data_ptr()\n",
    "print(f\"repeat 后的 storage 指针与原指针相同: {D_repeated_storage_ptr == D_storage_ptr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30. 综合应用：图像批次处理 (★★☆)\n",
    "任务: 假设你有一个批次的灰度图像数据，其形状为 (10, 1, 28, 28)，代表 10 张 28x28 的单通道图像。现在，你需要将其转换为 (10, 28, 28, 3)，模拟将灰度图转为 RGB 图（通过简单复制通道）。\n",
    "\n",
    "- 移除大小为 1 的通道维度。\n",
    "- 增加一个新的通道维度。\n",
    "- 将新的通道维度扩展为 3。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: squeeze(1) 后形状: torch.Size([10, 28, 28])\n",
      "Step 2: unsqueeze(-1) 后形状: torch.Size([10, 28, 28, 1])\n",
      "Step 3: expand 后的最终形状: torch.Size([10, 28, 28, 3])\n"
     ]
    }
   ],
   "source": [
    "# 模拟一个批次的图像数据 (N, C, H, W)\n",
    "batch_images = torch.randn(10, 1, 28, 28)\n",
    "\n",
    "# 1. 移除大小为 1 的通道维度 -> (10, 28, 28)\n",
    "squeezed_batch = batch_images.squeeze(1)\n",
    "print(f\"Step 1: squeeze(1) 后形状: {squeezed_batch.shape}\")\n",
    "\n",
    "# 2. 在末尾增加一个新的通道维度 -> (10, 28, 28, 1)\n",
    "unsqueezed_batch = squeezed_batch.unsqueeze(-1)\n",
    "print(f\"Step 2: unsqueeze(-1) 后形状: {unsqueezed_batch.shape}\")\n",
    "\n",
    "# 3. 使用 expand 将最后一个维度扩展为 3 -> (10, 28, 28, 3)\n",
    "rgb_batch = unsqueezed_batch.expand(-1, -1, -1, 3)\n",
    "print(f\"Step 3: expand 后的最终形状: {rgb_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31. 综合挑战：提取棋盘格点 (★★★)\n",
    "任务: 创建一个 8x8 的张量 E，代表一个棋盘，值为 0 到 63。你的任务是只提取出所有 \"白格\" 上的数字。假设左上角 (0, 0) 是白格，那么行索引和列索引之和为偶数的位置就是白格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始棋盘 (8x8) ---\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [16, 17, 18, 19, 20, 21, 22, 23],\n",
      "        [24, 25, 26, 27, 28, 29, 30, 31],\n",
      "        [32, 33, 34, 35, 36, 37, 38, 39],\n",
      "        [40, 41, 42, 43, 44, 45, 46, 47],\n",
      "        [48, 49, 50, 51, 52, 53, 54, 55],\n",
      "        [56, 57, 58, 59, 60, 61, 62, 63]])\n",
      "\n",
      "--- 白格掩码 ---\n",
      "tensor([[ True, False,  True, False,  True, False,  True, False],\n",
      "        [False,  True, False,  True, False,  True, False,  True],\n",
      "        [ True, False,  True, False,  True, False,  True, False],\n",
      "        [False,  True, False,  True, False,  True, False,  True],\n",
      "        [ True, False,  True, False,  True, False,  True, False],\n",
      "        [False,  True, False,  True, False,  True, False,  True],\n",
      "        [ True, False,  True, False,  True, False,  True, False],\n",
      "        [False,  True, False,  True, False,  True, False,  True]])\n",
      "\n",
      "--- 方法一提取出的所有白格元素 ---\n",
      "tensor([ 0,  2,  4,  6,  9, 11, 13, 15, 16, 18, 20, 22, 25, 27, 29, 31, 32, 34,\n",
      "        36, 38, 41, 43, 45, 47, 48, 50, 52, 54, 57, 59, 61, 63])\n",
      "共提取了 32 个元素\n",
      "--- 方法二计算得到的rows和cols ---\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [4, 4, 4, 4, 4, 4, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6],\n",
      "        [7, 7, 7, 7, 7, 7, 7, 7]]) tensor([[0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7]])\n",
      "\n",
      "--- 方法二提取出的所有白格元素 ---\n",
      "tensor([ 0,  2,  4,  6,  9, 11, 13, 15, 16, 18, 20, 22, 25, 27, 29, 31, 32, 34,\n",
      "        36, 38, 41, 43, 45, 47, 48, 50, 52, 54, 57, 59, 61, 63])\n",
      "共提取了 32 个元素\n"
     ]
    }
   ],
   "source": [
    "# --- 解法一 ---\n",
    "# 创建一个 8x8 的棋盘\n",
    "E = torch.arange(64).reshape(8, 8)\n",
    "\n",
    "# 创建行和列的索引网格\n",
    "rows = torch.arange(8).view(8, 1)\n",
    "cols = torch.arange(8).view(1, 8)\n",
    "\n",
    "# 计算每个位置的索引和（广播机制）\n",
    "index_sum = rows + cols\n",
    "\n",
    "# 创建布尔掩码，索引和为偶数的位置是 True\n",
    "mask = (index_sum % 2 == 0)\n",
    "\n",
    "# 使用布尔索引提取白格上的元素\n",
    "white_cells = E[mask]\n",
    "\n",
    "print(\"--- 原始棋盘 (8x8) ---\")\n",
    "print(E)\n",
    "print(\"\\n--- 白格掩码 ---\")\n",
    "print(mask)\n",
    "print(\"\\n--- 方法一提取出的所有白格元素 ---\")\n",
    "print(white_cells)\n",
    "print(f\"共提取了 {white_cells.numel()} 个元素\")\n",
    "\n",
    "\n",
    "# --- 解法二 ---\n",
    "rows, cols = torch.meshgrid(torch.arange(8), torch.arange(8), indexing='ij')\n",
    "white_cells = E[(rows + cols) % 2 == 0] # 无广播操作，因为rows和cols都是8x8的矩阵\n",
    "print(\"--- 方法二计算得到的rows和cols ---\")\n",
    "print(rows, cols)\n",
    "print(\"\\n--- 方法二提取出的所有白格元素 ---\")\n",
    "print(white_cells)\n",
    "print(f\"共提取了 {white_cells.numel()} 个元素\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32. 综合挑战：批量矩阵特定对角线提取 (★★★)\n",
    "任务: 假设你有一个形状为 (4, 5, 5) 的张量 F，代表一个批次的 4 个 5x5 矩阵。你需要提取出这 4 个矩阵的主对角线元素，最终得到一个形状为 (4, 5) 的张量。请思考如何高效完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始批次张量形状 ---\n",
      "torch.Size([4, 5, 5])\n",
      "\n",
      "--- 使用 torch.diagonal 提取的结果 (4, 5) ---\n",
      "tensor([[ 0,  6, 12, 18, 24],\n",
      "        [25, 31, 37, 43, 49],\n",
      "        [50, 56, 62, 68, 74],\n",
      "        [75, 81, 87, 93, 99]])\n",
      "\n",
      "--- 使用手动索引提取的结果 (4, 5) ---\n",
      "tensor([[ 0,  6, 12, 18, 24],\n",
      "        [25, 31, 37, 43, 49],\n",
      "        [50, 56, 62, 68, 74],\n",
      "        [75, 81, 87, 93, 99]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个批次的矩阵\n",
    "F = torch.arange(4 * 5 * 5).reshape(4, 5, 5)\n",
    "\n",
    "# 方法一：使用 gather\n",
    "# 我们需要一个索引张量，告诉 gather 去哪里取值\n",
    "# 对于第 k 个矩阵，我们要取 (k, 0, 0), (k, 1, 1), ..., (k, 4, 4)\n",
    "# 这很难用一次 gather 完成。\n",
    "\n",
    "\n",
    "# 方法二：使用 torch.diagonal(F, offset=0, dim1=1, dim2=2)\n",
    "# offset=0 表示主对角线，dim1和dim2构成了一个平面，函数在这个平面上取对角线\n",
    "# 这是最直接、最简洁的方法\n",
    "diagonals_direct = torch.diagonal(F, offset=0, dim1=1, dim2=2)\n",
    "\n",
    "\n",
    "# 方法三：手动构造索引 (更底层，有助于理解)\n",
    "# 创建一个范围 [0, 1, 2, 3, 4]\n",
    "indices = torch.arange(5)\n",
    "# F[:, indices, indices] 这种索引方式在 PyTorch 中可以直接使用\n",
    "diagonals_manual = F[:, indices, indices]\n",
    "\n",
    "print(\"--- 原始批次张量形状 ---\")\n",
    "print(F.shape)\n",
    "# print(\"\\n--- 使用 gather 提取的结果 (4, 5) ---\")\n",
    "# print(diagonals_gather)\n",
    "print(\"\\n--- 使用 torch.diagonal 提取的结果 (4, 5) ---\")\n",
    "print(diagonals_direct)\n",
    "print(\"\\n--- 使用手动索引提取的结果 (4, 5) ---\")\n",
    "print(diagonals_manual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33. 综合挑战：翻转序列 (★★☆)\n",
    "任务: 给定一个形状为 (5, 10) 的张量 G，代表 5 个长度为 10 的序列。请将每个序列独立地进行翻转，得到一个同样形状为 (5, 10) 的新张量，其中每一行都是原始行的逆序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这种写法在numpy中支持，但在PyTorch中不支持\n",
      "\n",
      "--- 原始序列批次 (5, 10) ---\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
      "        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]])\n",
      "\n",
      "--- 使用torch.flip()翻转每个序列后的结果 ---\n",
      "tensor([[ 9,  8,  7,  6,  5,  4,  3,  2,  1,  0],\n",
      "        [19, 18, 17, 16, 15, 14, 13, 12, 11, 10],\n",
      "        [29, 28, 27, 26, 25, 24, 23, 22, 21, 20],\n",
      "        [39, 38, 37, 36, 35, 34, 33, 32, 31, 30],\n",
      "        [49, 48, 47, 46, 45, 44, 43, 42, 41, 40]])\n",
      "\n",
      "--- 使用索引翻转每个序列后的结果 ---\n",
      "tensor([[ 9,  8,  7,  6,  5,  4,  3,  2,  1,  0],\n",
      "        [19, 18, 17, 16, 15, 14, 13, 12, 11, 10],\n",
      "        [29, 28, 27, 26, 25, 24, 23, 22, 21, 20],\n",
      "        [39, 38, 37, 36, 35, 34, 33, 32, 31, 30],\n",
      "        [49, 48, 47, 46, 45, 44, 43, 42, 41, 40]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个批次的序列\n",
    "G = torch.arange(50).reshape(5, 10)\n",
    "\n",
    "# --- 方法一 ---\n",
    "# 使用 `torch.flip()` 函数，指定要翻转的维度\n",
    "# dims控制反转的维度以及反转的顺序，[1]表示在第二个维度上反转\n",
    "G_flipped = torch.flip(G, dims=[1])\n",
    "\n",
    "# --- 方法二 ---\n",
    "# 使用索引反转每个序列\n",
    "G_flipped_index = G[:, torch.arange(G.size(1)-1, -1, -1)]\n",
    "\n",
    "# 也可以使用倒序列表作为索引下标，但是思路相同\n",
    "# index = [i for i in range(G.size(1)-1, -1, -1)]\n",
    "# G_flipped_index = G[:, index]\n",
    "\n",
    "# --- 方法三 ---\n",
    "# 使用切片反转每个序列\n",
    "# 语法 G[:, ::-1] 但在PyTorch中需要用专门的索引表示法\n",
    "try:\n",
    "    G_flipped_slice = G[:, ::-1]\n",
    "except:\n",
    "    print(\"这种写法在numpy中支持，但在PyTorch中不支持\\n\")\n",
    "\n",
    "print(\"--- 原始序列批次 (5, 10) ---\")\n",
    "print(G)\n",
    "print(\"\\n--- 使用torch.flip()翻转每个序列后的结果 ---\")\n",
    "print(G_flipped)\n",
    "print(\"\\n--- 使用索引翻转每个序列后的结果 ---\")\n",
    "print(G_flipped_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 34. 综合挑战：创建 One-Hot 编码 (★★★)\n",
    "任务: One-Hot 编码是分类任务中常用的数据预处理步骤。给定一个包含类别索引的一维张量 labels = torch.tensor([0, 2, 1, 4]) 和类别总数 num_classes = 5，请创建一个 4x5 的 One-Hot 编码张量。每一行对应一个标签，该行中标签索引的位置为 1，其余为 0。请尝试用 scatter_ 实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始标签 ---\n",
      "tensor([0, 2, 1, 4])\n",
      "\n",
      "--- 转换后的 One-Hot 编码张量 (4x5) ---\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 输入的标签和类别总数\n",
    "labels = torch.tensor([0, 2, 1, 4])\n",
    "num_classes = 5\n",
    "num_labels = labels.shape[0]\n",
    "\n",
    "# 1. 创建一个全零的目标张量 [4,5]\n",
    "one_hot = torch.zeros(num_labels, num_classes)\n",
    "\n",
    "# 2. 准备 scatter_ 需要的 index 张量\n",
    "# labels 需要是 (4, 1) 的形状，以指定每一行要修改的列索引\n",
    "index = labels.unsqueeze(1)\n",
    "\n",
    "# 3. 使用 scatter_ 填充\n",
    "# 在 dim=1 (列方向) 上操作\n",
    "# 对于 one_hot 的第 i 行，在 index[i] (也就是 labels[i]) 指定的列上，填入值 1\n",
    "one_hot.scatter_(dim=1, index=index, value=1.0)\n",
    "\n",
    "\n",
    "print(\"--- 原始标签 ---\")\n",
    "print(labels)\n",
    "print(\"\\n--- 转换后的 One-Hot 编码张量 (4x5) ---\")\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 35. 终极挑战：块交换 (★★★)\n",
    "任务: 创建一个 6x6 的张量 H。将其在两个维度上都均匀切分成 4 个 3x3 的块，然后将这 4 个块进行对角线交换（左上与右下交换，右上与左下交换）。\n",
    "\n",
    "原始布局: [[A, B], [C, D]]\n",
    "目标布局: [[D, C], [B, A]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 H (6x6) ---\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23],\n",
      "        [24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35]])\n",
      "\n",
      "--- 左上块 A ---\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 6,  7,  8],\n",
      "        [12, 13, 14]])\n",
      "--- 右上块 B ---\n",
      "tensor([[ 3,  4,  5],\n",
      "        [ 9, 10, 11],\n",
      "        [15, 16, 17]])\n",
      "--- 左下块 C ---\n",
      "tensor([[18, 19, 20],\n",
      "        [24, 25, 26],\n",
      "        [30, 31, 32]])\n",
      "--- 右下块 D ---\n",
      "tensor([[21, 22, 23],\n",
      "        [27, 28, 29],\n",
      "        [33, 34, 35]])\n",
      "\n",
      "--- 交换块后的最终结果 ---\n",
      "tensor([[21, 22, 23, 18, 19, 20],\n",
      "        [27, 28, 29, 24, 25, 26],\n",
      "        [33, 34, 35, 30, 31, 32],\n",
      "        [ 3,  4,  5,  0,  1,  2],\n",
      "        [ 9, 10, 11,  6,  7,  8],\n",
      "        [15, 16, 17, 12, 13, 14]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 6x6 张量\n",
    "H = torch.arange(36).reshape(6, 6)\n",
    "\n",
    "# 1. 将 H 分割成 4 个 3x3 的块\n",
    "# 先沿行分割\n",
    "H_top, H_bottom = torch.chunk(H, 2, dim=0)\n",
    "# 再对上下两部分分别沿列分割\n",
    "A, B = torch.chunk(H_top, 2, dim=1)\n",
    "C, D = torch.chunk(H_bottom, 2, dim=1)\n",
    "\n",
    "# 2. 按照新的布局重新拼接\n",
    "# 创建新的顶行 [D, C] 和底行 [B, A]\n",
    "new_top_row = torch.cat((D, C), dim=1)\n",
    "new_bottom_row = torch.cat((B, A), dim=1)\n",
    "\n",
    "# 将新的两行沿行方向拼接\n",
    "result = torch.cat((new_top_row, new_bottom_row), dim=0)\n",
    "\n",
    "print(\"--- 原始张量 H (6x6) ---\")\n",
    "print(H)\n",
    "print(\"\\n--- 左上块 A ---\")\n",
    "print(A)\n",
    "print(\"--- 右上块 B ---\")\n",
    "print(B)\n",
    "print(\"--- 左下块 C ---\")\n",
    "print(C)\n",
    "print(\"--- 右下块 D ---\")\n",
    "print(D)\n",
    "print(\"\\n--- 交换块后的最终结果 ---\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模块三：数学与逻辑运算 🧮\n",
    "掌握张量的数值计算，这是构建神经网络前向传播的基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 36. 基础运算与广播 (★★☆)\n",
    "任务: 创建一个形状为 (4, 1) 的张量 A 和一个形状为 (1, 3) 的张量 B。\n",
    "\n",
    "计算 A 和 B 的和得到张量 C ，并解释结果的形状为何是 (4, 3)。\n",
    "计算 C 中各元素的自然指数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 A (4x1) ---\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n",
      "\n",
      "--- 原始张量 B (1x3) ---\n",
      "tensor([[0, 1, 2]])\n",
      "\n",
      "--- A + B 的计算结果 (4x3) ---\n",
      "tensor([[0, 1, 2],\n",
      "        [1, 2, 3],\n",
      "        [2, 3, 4],\n",
      "        [3, 4, 5]])\n",
      "结果形状: torch.Size([4, 3])\n",
      "\n",
      "--- C 的自然指数结果 ---\n",
      "tensor([[  1.0000,   2.7183,   7.3891],\n",
      "        [  2.7183,   7.3891,  20.0855],\n",
      "        [  7.3891,  20.0855,  54.5981],\n",
      "        [ 20.0855,  54.5981, 148.4132]])\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建张量\n",
    "A = torch.arange(4).view(4, 1)\n",
    "B = torch.arange(3).view(1, 3)\n",
    "print(\"--- 原始张量 A (4x1) ---\")\n",
    "print(A)\n",
    "print(\"\\n--- 原始张量 B (1x3) ---\")\n",
    "print(B)\n",
    "\n",
    "# 2. 计算和，触发广播机制\n",
    "# A 的形状是 (4, 1)，B 的形状是 (1, 3)\n",
    "# 广播后，A 变为 (4, 3)，B 变为 (4, 3)，然后逐元素相加\n",
    "C = A + B\n",
    "print(\"\\n--- A + B 的计算结果 (4x3) ---\")\n",
    "print(C)\n",
    "print(f\"结果形状: {C.shape}\")\n",
    "\n",
    "# 3. 计算自然指数\n",
    "C_exp = torch.exp(C.float()) # exp需要浮点数输入\n",
    "print(\"\\n--- C 的自然指数结果 ---\")\n",
    "print(C_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 37. 元素处理组合 (★★☆)\n",
    "任务: 创建一个在 (-10, 10) 区间内均匀分布的 (3, 3) 随机张量 X。\n",
    "\n",
    "- 计算其所有元素的绝对值。\n",
    "- 将原始张量 X 的所有元素值限制在 [-5, 5] 区间内，超出范围的值赋值为区间边缘值（-5或5）。\n",
    "- 对限制范围后的结果进行四舍五入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 X ---\n",
      "tensor([[-0.8383, -0.3429, -3.7500],\n",
      "        [ 2.3004, -5.7211, -1.7635],\n",
      "        [ 3.8759,  9.3862,  2.3559]])\n",
      "\n",
      "--- X 的绝对值 ---\n",
      "tensor([[0.8383, 0.3429, 3.7500],\n",
      "        [2.3004, 5.7211, 1.7635],\n",
      "        [3.8759, 9.3862, 2.3559]])\n",
      "\n",
      "--- 将 X 限制在 [-5, 5] 内的结果 ---\n",
      "tensor([[-0.8383, -0.3429, -3.7500],\n",
      "        [ 2.3004, -5.0000, -1.7635],\n",
      "        [ 3.8759,  5.0000,  2.3559]])\n",
      "\n",
      "--- 四舍五入后的结果 ---\n",
      "X_rounded: tensor([[-1., -0., -4.],\n",
      "        [ 2., -5., -2.],\n",
      "        [ 4.,  5.,  2.]])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以复现结果\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# 1. 创建张量\n",
    "X = (torch.rand(3, 3) * 20) - 10 # 转换为 (-10, 10) 范围\n",
    "print(\"--- 原始张量 X ---\")\n",
    "print(X)\n",
    "\n",
    "# 2. 计算绝对值\n",
    "X_abs = torch.abs(X)\n",
    "print(\"\\n--- X 的绝对值 ---\")\n",
    "print(X_abs)\n",
    "\n",
    "# 3. 限制元素范围\n",
    "X_clamped = torch.clamp(X, min=-5, max=5)\n",
    "print(\"\\n--- 将 X 限制在 [-5, 5] 内的结果 ---\")\n",
    "print(X_clamped)\n",
    "\n",
    "# 4. 对结果进行四舍五入\n",
    "X_rounded = torch.round(X_clamped)\n",
    "print(\"\\n--- 四舍五入后的结果 ---\")\n",
    "print(\"X_rounded:\",X_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 38. 矩阵乘法的核心区别 (★★☆)\n",
    "任务: 创建两个形状均为 (2, 3) 的随机张量 A 和 B。\n",
    "\n",
    "- 计算 A 与 B 的逐元素乘积。\n",
    "- 计算 A 与 B 的转置（B.T）的矩阵乘积。\n",
    "- 解释两种乘法在计算方式和结果形状上的根本不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 A (2x3) ---\n",
      "tensor([[-1.2061,  0.0617,  1.1632],\n",
      "        [-1.5008, -1.5944, -0.0187]])\n",
      "\n",
      "--- 原始张量 B (2x3) ---\n",
      "tensor([[-2.1325, -0.5270, -0.1021],\n",
      "        [ 0.0099, -0.4454, -1.4976]])\n",
      "\n",
      "--- 逐元素乘积 (A * B) 的结果 (2x3) ---\n",
      "tensor([[ 2.5719, -0.0325, -0.1188],\n",
      "        [-0.0149,  0.7102,  0.0280]])\n",
      "\n",
      "--- 矩阵乘积的结果 (2x2) ---\n",
      "tensor([[ 2.4207, -1.7813],\n",
      "        [ 4.0427,  0.7234]])\n",
      "tensor([[ 2.4207, -1.7813],\n",
      "        [ 4.0427,  0.7234]])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(20)\n",
    "\n",
    "# 1. 创建张量\n",
    "A = torch.randn(2, 3)\n",
    "B = torch.randn(2, 3)\n",
    "print(\"--- 原始张量 A (2x3) ---\")\n",
    "print(A)\n",
    "print(\"\\n--- 原始张量 B (2x3) ---\")\n",
    "print(B)\n",
    "\n",
    "# 2. 逐元素乘法\n",
    "# 要求两个张量形状相同，结果张量形状也与之相同\n",
    "element_wise_prod = A * B\n",
    "print(\"\\n--- 逐元素乘积 (A * B) 的结果 (2x3) ---\")\n",
    "print(element_wise_prod)\n",
    "\n",
    "# 3. 矩阵乘法\n",
    "# 要求第一个张量的列数等于第二个张量的行数\n",
    "# A(2x3) @ B.T(3x2) -> 结果为 (2x2)\n",
    "matrix_prod = A @ B.T\n",
    "matrix_prod_2 = torch.matmul(A, B.T)\n",
    "print(\"\\n--- 矩阵乘积的结果 (2x2) ---\")\n",
    "print(matrix_prod)\n",
    "print(matrix_prod_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 39. 矩阵向量点积运算 (★★☆)\n",
    "任务: 创建一个 (4, 2) 的矩阵 M 和一个长度为 2 的向量 V。\n",
    "\n",
    "- 计算矩阵与向量的乘积。\n",
    "- 提取 M 的第一行 row1，并计算 row1 与向量 V 的点积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 矩阵 M (4x2) ---\n",
      "tensor([[0., 1.],\n",
      "        [2., 3.],\n",
      "        [4., 5.],\n",
      "        [6., 7.]])\n",
      "\n",
      "--- 向量 V (长度为2) ---\n",
      "tensor([2., 3.])\n",
      "\n",
      "--- 矩阵-向量乘积结果1 (长度为4) ---\n",
      "tensor([ 3., 13., 23., 33.])\n",
      "\n",
      "--- 矩阵-向量乘积结果2 (长度为4) ---\n",
      "tensor([ 3., 13., 23., 33.])\n",
      "\n",
      "--- 矩阵-向量乘积结果3 (长度为4) ---\n",
      "tensor([ 3., 13., 23., 33.])\n",
      "\n",
      "--- M的第一行 ([0. 1.]) 与 V 的点积结果 ---\n",
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建张量\n",
    "M = torch.arange(8).float().reshape(4, 2)\n",
    "V = torch.tensor([2.0, 3.0])\n",
    "print(\"--- 矩阵 M (4x2) ---\")\n",
    "print(M)\n",
    "print(\"\\n--- 向量 V (长度为2) ---\")\n",
    "print(V)\n",
    "\n",
    "# 2. 计算矩阵-向量乘积\n",
    "# 结果是一个长度为4的向量\n",
    "# 注意：不论V向量是否转置，PyTorch都可以自动处理\n",
    "mv_prod = torch.mv(M, V)\n",
    "print(\"\\n--- 矩阵-向量乘积结果1 (长度为4) ---\")\n",
    "print(mv_prod)\n",
    "\n",
    "mv_prod_2 = M @ V\n",
    "print(\"\\n--- 矩阵-向量乘积结果2 (长度为4) ---\")\n",
    "print(mv_prod_2)\n",
    "\n",
    "mv_prod_3 = torch.matmul(M, V)\n",
    "print(\"\\n--- 矩阵-向量乘积结果3 (长度为4) ---\")\n",
    "print(mv_prod_3)\n",
    "\n",
    "\n",
    "# 3. 计算点积\n",
    "row1 = M[0, :]\n",
    "dot_prod = torch.dot(row1, V)\n",
    "print(f\"\\n--- M的第一行 ({row1.numpy()}) 与 V 的点积结果 ---\")\n",
    "print(dot_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 40. 三角函数应用 (★★☆)\n",
    "任务: 创建一个从 0 到 2π 均匀间隔的10个点的一维张量 theta。\n",
    "\n",
    "- 计算 theta 所有元素的正弦和余弦值。\n",
    "- 验证 \"正弦值的平方\" 与 \"余弦值的平方\" 之和，其结果张量中所有元素都近似为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 角度张量 theta ---\n",
      "tensor([0.0000, 0.6981, 1.3963, 2.0944, 2.7925, 3.4907, 4.1888, 4.8869, 5.5851,\n",
      "        6.2832])\n",
      "\n",
      "--- 正弦值 ---\n",
      "tensor([ 0.0000e+00,  6.4279e-01,  9.8481e-01,  8.6603e-01,  3.4202e-01,\n",
      "        -3.4202e-01, -8.6603e-01, -9.8481e-01, -6.4279e-01,  1.7485e-07])\n",
      "\n",
      "--- 余弦值 ---\n",
      "tensor([ 1.0000,  0.7660,  0.1736, -0.5000, -0.9397, -0.9397, -0.5000,  0.1736,\n",
      "         0.7660,  1.0000])\n",
      "\n",
      "--- sin^2 + cos^2 的结果 (应近似为1) ---\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建角度张量\n",
    "# 与numpy不同，torch.linspace()默认包含结束点\n",
    "theta = torch.linspace(0, 2 * torch.pi, 10)\n",
    "print(\"--- 角度张量 theta ---\")\n",
    "print(theta)\n",
    "\n",
    "# 2. 计算正弦和余弦\n",
    "sin_theta = torch.sin(theta)\n",
    "cos_theta = torch.cos(theta)\n",
    "print(\"\\n--- 正弦值 ---\")\n",
    "print(sin_theta)\n",
    "print(\"\\n--- 余弦值 ---\")\n",
    "print(cos_theta)\n",
    "\n",
    "# 3. 验证 sin^2 + cos^2 = 1\n",
    "sum_of_squares = sin_theta.pow(2) + cos_theta.pow(2)\n",
    "print(\"\\n--- sin^2 + cos^2 的结果 (应近似为1) ---\")\n",
    "print(sum_of_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 41. 基础聚合操作 (★★☆)\n",
    "任务: 创建一个 (5, 4) 的随机整数张量，计算整个张量的 总和、均值 和 标准差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 X (5x4) ---\n",
      "tensor([[17., 17., 17., 13.],\n",
      "        [16.,  4., 19.,  2.],\n",
      "        [17.,  7.,  5.,  6.],\n",
      "        [11.,  5., 19.,  7.],\n",
      "        [ 9.,  9.,  5.,  9.]])\n",
      "\n",
      "--- 聚合计算结果 ---\n",
      "总和: 214.00\n",
      "均值: 10.70\n",
      "标准差: 5.65\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(30)\n",
    "\n",
    "# 1. 创建张量\n",
    "X = torch.randint(0, 20, (5, 4)).float() # 转换为浮点数以便计算均值和标准差\n",
    "print(\"--- 原始张量 X (5x4) ---\")\n",
    "print(X)\n",
    "\n",
    "# 2. 计算聚合值\n",
    "total_sum = X.sum()\n",
    "mean_val = X.mean()\n",
    "std_val = X.std()\n",
    "\n",
    "\n",
    "print(f\"\\n--- 聚合计算结果 ---\")\n",
    "print(f\"总和: {total_sum.item():.2f}\")\n",
    "print(f\"均值: {mean_val.item():.2f}\")\n",
    "print(f\"标准差: {std_val.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 42. 按维度聚合与 keepdim (★★☆)\n",
    "任务: 对于一个 (5, 4) 的随机张量，分别计算 每一列 的 **总和** 和 每一行 的 **均值**。其中，在计算行均值时，请设置参数以保持结果的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 X (5x4) ---\n",
      "tensor([[ 0.1838,  0.1832, -2.3538, -0.1817],\n",
      "        [-0.2994, -2.1561,  0.4940,  2.4608],\n",
      "        [-1.2028,  0.8062,  1.2355, -0.5087],\n",
      "        [-2.5162,  0.1458,  1.5299,  0.9691],\n",
      "        [-0.7181, -1.6961,  1.0695, -0.9444]])\n",
      "\n",
      "--- 每一列的总和 (dim=0) ---\n",
      "tensor([-4.5527, -2.7169,  1.9752,  1.7952])\n",
      "结果形状: torch.Size([4])\n",
      "\n",
      "--- 每一行的均值 (dim=1, keepdim=True) ---\n",
      "tensor([[-0.5421],\n",
      "        [ 0.1248],\n",
      "        [ 0.0826],\n",
      "        [ 0.0322],\n",
      "        [-0.5723]])\n",
      "结果形状: torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(35)\n",
    "X = torch.randn(5, 4)\n",
    "print(\"--- 原始张量 X (5x4) ---\")\n",
    "print(X)\n",
    "\n",
    "# 1. 计算每一列的总和 (沿 dim=0 聚合)\n",
    "# 结果形状为 (4,)\n",
    "col_sum = X.sum(dim=0)\n",
    "print(\"\\n--- 每一列的总和 (dim=0) ---\")\n",
    "print(col_sum)\n",
    "print(f\"结果形状: {col_sum.shape}\")\n",
    "\n",
    "# 2. 计算每一行的均值，并保持维度\n",
    "# 结果形状应为 (5, 1) 而不是 (5,)\n",
    "row_mean_keepdim = X.mean(dim=1, keepdim=True)\n",
    "print(\"\\n--- 每一行的均值 (dim=1, keepdim=True) ---\")\n",
    "print(row_mean_keepdim)\n",
    "print(f\"结果形状: {row_mean_keepdim.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 43. 查找最值及其索引 (★★☆)\n",
    "任务: 创建一个 (3, 4) 的随机张量。\n",
    "\n",
    "- 找出整个张量的最大值。\n",
    "- 找出每一行中的最大值及其对应的列索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 X (3x4) ---\n",
      "tensor([[ 0.9307, -0.3482,  0.8855, -0.4909],\n",
      "        [-0.4273,  0.9385,  1.1841,  0.5234],\n",
      "        [ 0.5403, -0.8986,  1.0984, -0.2616]])\n",
      "\n",
      "--- 全局最大值 ---\n",
      "1.1840680837631226\n",
      "\n",
      "--- 每一行的最大值 ---\n",
      "tensor([0.9307, 1.1841, 1.0984])\n",
      "\n",
      "--- 每一行最大值对应的列索引 ---\n",
      "tensor([0, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(40)\n",
    "X = torch.randn(3, 4)\n",
    "print(\"--- 原始张量 X (3x4) ---\")\n",
    "print(X)\n",
    "\n",
    "# 1. 找出全局最大值\n",
    "global_max = X.max()\n",
    "print(f\"\\n--- 全局最大值 ---\")\n",
    "print(global_max.item())\n",
    "\n",
    "# 2. 找出每一行的最大值及其索引\n",
    "# 函数会返回一个包含(值, 索引)的元组\n",
    "row_max_values, row_max_indices = X.max(dim=1)\n",
    "print(\"\\n--- 每一行的最大值 ---\")\n",
    "print(row_max_values)\n",
    "print(\"\\n--- 每一行最大值对应的列索引 ---\")\n",
    "print(row_max_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 44. 向量与矩阵范数 (★★☆)\n",
    "任务: 创建一个 (2, 3) 的张量 X，计算其 L1范数 (所有元素的绝对值之和) 和 L2范数 (所有元素的平方和再开方，也称Frobenius范数)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 X (2x3) ---\n",
      "tensor([[-3., -2., -1.],\n",
      "        [ 0.,  1.,  2.]])\n",
      "\n",
      "--- L1 范数 ---\n",
      "tensor(9.)\n",
      "\n",
      "--- L2 范数 ---\n",
      "tensor(4.3589)\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建张量\n",
    "X = torch.arange(-3, 3).view(2, 3).float()\n",
    "print(\"--- 原始张量 X (2x3) ---\")\n",
    "print(X)\n",
    "\n",
    "# 2. 计算L1范数\n",
    "l1_norm = torch.norm(X, p=1)\n",
    "print(f\"\\n--- L1 范数 ---\")\n",
    "print(l1_norm)\n",
    "\n",
    "# 3. 计算L2范数 (Frobenius Norm)\n",
    "l2_norm = torch.norm(X, p=2)\n",
    "print(f\"\\n--- L2 范数 ---\")\n",
    "print(l2_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 45. 累积运算 (★★☆)\n",
    "任务: 创建一个一维整数张量 T，并计算其 累积和 与 累积积。\n",
    "- 累积和：沿着指定维度，计算到当前位置为止的所有元素之和\n",
    "例如对于张量 [1,2,3,4,5]\n",
    "累积和为 [1, 1+2, 1+2+3, 1+2+3+4, 1+2+3+4+5] = [1, 3, 6, 10, 15]\n",
    "- 累积积：沿着指定维度，计算到当前位置为止的所有元素之积\n",
    "例如对于张量 [1,2,3,4,5]\n",
    "累积积为 [1, 1×2, 1×2×3, 1×2×3×4, 1×2×3×4×5] = [1, 2, 6, 24, 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 T ---\n",
      "tensor([1, 2, 3, 4, 5])\n",
      "\n",
      "--- T 的累积和 ---\n",
      "tensor([ 1,  3,  6, 10, 15])\n",
      "\n",
      "--- T 的累积积 ---\n",
      "tensor([  1,   2,   6,  24, 120])\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建张量\n",
    "T = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(\"--- 原始张量 T ---\")\n",
    "print(T)\n",
    "\n",
    "# 2. 计算累积和\n",
    "T_cumsum = torch.cumsum(T, dim=0)\n",
    "print(\"\\n--- T 的累积和 ---\")\n",
    "print(T_cumsum)\n",
    "\n",
    "# 3. 计算累积积\n",
    "T_cumprod = torch.cumprod(T, dim=0)\n",
    "print(\"\\n--- T 的累积积 ---\")\n",
    "print(T_cumprod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 46. 张量比较与逻辑聚合 (★★☆)\n",
    "任务: 创建两个 (3, 3) 的随机整数张量 A 和 B (范围0-9)。\n",
    "\n",
    "- 生成一个布尔张量，表示 A 中大于 B 的位置。\n",
    "- 判断 A 是否所有元素都大于0，以及 B 是否至少有一个元素等于7。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 A ---\n",
      "tensor([[4, 8, 3],\n",
      "        [1, 9, 0],\n",
      "        [4, 0, 5]])\n",
      "\n",
      "--- 原始张量 B ---\n",
      "tensor([[4, 8, 7],\n",
      "        [5, 0, 7],\n",
      "        [0, 9, 1]])\n",
      "\n",
      "--- A > B 的布尔掩码 ---\n",
      "tensor([[False, False, False],\n",
      "        [False,  True, False],\n",
      "        [ True, False,  True]])\n",
      "\n",
      "--- 逻辑判断结果 ---\n",
      "A 的所有元素都大于0吗? False\n",
      "B 中至少有一个元素等于7吗? True\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(50)\n",
    "A = torch.randint(0, 10, (3, 3))\n",
    "B = torch.randint(0, 10, (3, 3))\n",
    "print(\"--- 原始张量 A ---\")\n",
    "print(A)\n",
    "print(\"\\n--- 原始张量 B ---\")\n",
    "print(B)\n",
    "\n",
    "# 1. 生成布尔掩码\n",
    "mask = A > B\n",
    "print(\"\\n--- A > B 的布尔掩码 ---\")\n",
    "print(mask)\n",
    "\n",
    "# 2. 逻辑聚合\n",
    "all_A_positive = torch.all(A > 0)\n",
    "any_B_is_7 = torch.any(B == 7)\n",
    "print(f\"\\n--- 逻辑判断结果 ---\")\n",
    "print(f\"A 的所有元素都大于0吗? {all_A_positive.item()}\")\n",
    "print(f\"B 中至少有一个元素等于7吗? {any_B_is_7.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 47. 条件选择 (★★☆)\n",
    "任务: 创建一个 (4, 4) 的标准正态分布随机张量。使用一个操作，将所有大于0.5的元素替换为1，小于-0.5的元素替换为-1，其余元素保持不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 X ---\n",
      "tensor([[ 0.1344, -0.7056,  1.8908,  0.2333],\n",
      "        [ 1.1136, -0.8451, -0.2718, -0.6904],\n",
      "        [ 0.1722, -0.4964, -0.5750, -1.1525],\n",
      "        [ 1.1892,  1.2960, -1.0281,  1.4255]])\n",
      "\n",
      "--- 条件替换后的结果 ---\n",
      "tensor([[ 0.1344, -1.0000,  1.0000,  0.2333],\n",
      "        [ 1.0000, -1.0000, -0.2718, -1.0000],\n",
      "        [ 0.1722, -0.4964, -1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000, -1.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(60)\n",
    "X = torch.randn(4, 4)\n",
    "print(\"--- 原始张量 X ---\")\n",
    "print(X)\n",
    "\n",
    "# 1. 嵌套条件选择\n",
    "# where(condition, x, y): 当条件为True时取x，否则取y\n",
    "# 先将 > 0.5 的替换为 1\n",
    "result = torch.where(X > 0.5, 1.0, X)\n",
    "# 再对上一步结果中 < -0.5 的替换为 -1\n",
    "result = torch.where(result < -0.5, -1.0, result)\n",
    "\n",
    "print(\"\\n--- 条件替换后的结果 ---\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 48. 频率统计 (★★★)\n",
    "任务: 创建一个包含 [0, 1, 2, 1, 2, 2, 0, 4, 2] 的一维整数张量 labels，高效地统计每个数字（类别）出现的次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始标签张量 ---\n",
      "tensor([0, 1, 2, 1, 2, 2, 0, 4, 2])\n",
      "\n",
      "--- 各类别出现次数统计 ---\n",
      "tensor([2, 2, 4, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建标签张量\n",
    "labels = torch.tensor([0, 1, 2, 1, 2, 2, 0, 4, 2])\n",
    "print(\"--- 原始标签张量 ---\")\n",
    "print(labels)\n",
    "\n",
    "# 2. 统计频率\n",
    "# 结果张量的索引代表类别，值代表该类别的数量\n",
    "# minlength确保即使最大标签4不存在，结果张量的长度也至少为5\n",
    "counts = torch.bincount(labels, minlength=5)\n",
    "print(\"\\n--- 各类别出现次数统计 ---\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 49. 综合应用：数据标准化 (★★★)\n",
    "任务: 创建一个 (10, 5) 的随机张量 D，并将第2列所有元素赋值为5。对 D 的每一列（特征）进行 Z-Score 标准化（使其均值为0，标准差为1）。请注意处理标准差为零的边缘情况（此时该列所有元素应变为0）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始数据 D ---\n",
      "tensor([[ 0.8271, -0.8417,  5.0000, -0.2040,  1.4320],\n",
      "        [-0.5107,  1.5798,  5.0000,  0.6767, -0.4259],\n",
      "        [-0.5820,  0.7566,  5.0000,  0.1647,  0.2752],\n",
      "        [-0.1702, -0.6664,  5.0000, -1.2822,  0.7640],\n",
      "        [ 0.9887,  1.7393,  5.0000, -1.5190,  0.6253],\n",
      "        [ 0.4719,  1.4954,  5.0000,  2.4252, -0.5634],\n",
      "        [ 0.5487,  1.2654,  5.0000,  0.4422, -0.5691],\n",
      "        [-0.1377,  1.6001,  5.0000, -1.5182, -0.6699],\n",
      "        [ 0.5538,  0.0637,  5.0000, -1.2409,  0.1662],\n",
      "        [-0.7296,  0.5355,  5.0000,  0.0094,  0.4708]])\n",
      "\n",
      "--- 每列的均值 ---\n",
      "tensor([ 0.1260,  0.7528,  5.0000, -0.2046,  0.1505])\n",
      "\n",
      "--- 每列的标准差 ---\n",
      "tensor([0.6248, 0.9585, 0.0000, 1.2464, 0.6988])\n",
      "\n",
      "--- 标准化后的数据 ---\n",
      "tensor([[ 1.1221e+00, -1.6636e+00,  0.0000e+00,  5.0551e-04,  1.8338e+00],\n",
      "        [-1.0191e+00,  8.6289e-01,  0.0000e+00,  7.0708e-01, -8.2480e-01],\n",
      "        [-1.1331e+00,  4.0492e-03,  0.0000e+00,  2.9629e-01,  1.7840e-01],\n",
      "        [-4.7402e-01, -1.4806e+00,  0.0000e+00, -8.6459e-01,  8.7785e-01],\n",
      "        [ 1.3809e+00,  1.0293e+00,  0.0000e+00, -1.0545e+00,  6.7940e-01],\n",
      "        [ 5.5361e-01,  7.7476e-01,  0.0000e+00,  2.1099e+00, -1.0216e+00],\n",
      "        [ 6.7654e-01,  5.3486e-01,  0.0000e+00,  5.1898e-01, -1.0298e+00],\n",
      "        [-4.2209e-01,  8.8401e-01,  0.0000e+00, -1.0539e+00, -1.1741e+00],\n",
      "        [ 6.8472e-01, -7.1895e-01,  0.0000e+00, -8.3144e-01,  2.2502e-02],\n",
      "        [-1.3695e+00, -2.2671e-01,  0.0000e+00,  1.7168e-01,  4.5830e-01]])\n",
      "\n",
      "--- 验证标准化后数据的均值和标准差（应接近0和1）---\n",
      "新均值: tensor([ 1.1921e-08, -5.9605e-08,  0.0000e+00,  3.5763e-08, -4.7684e-08])\n",
      "新标准差: tensor([1.0000, 1.0000, 0.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(70)\n",
    "D = torch.randn(10, 5)\n",
    "# 人为制造一个标准差为0的列\n",
    "D[:, 2] = 5.0\n",
    "print(\"--- 原始数据 D ---\")\n",
    "print(D)\n",
    "\n",
    "# 1. 计算均值和标准差\n",
    "mean_D = D.mean(dim=0)\n",
    "std_D = D.std(dim=0)\n",
    "print(\"\\n--- 每列的均值 ---\")\n",
    "print(mean_D)\n",
    "print(\"\\n--- 每列的标准差 ---\")\n",
    "print(std_D)\n",
    "\n",
    "# 2. 进行标准化\n",
    "# 增加一个极小值 epsilon 防止除以零\n",
    "epsilon = 1e-8\n",
    "D_normalized = (D - mean_D) / (std_D + epsilon)\n",
    "\n",
    "# 检查标准差为0的列是否正确处理（或者直接将其设为0）\n",
    "# D_normalized[:, std_D == 0] = 0 # 更稳健的做法\n",
    "\n",
    "print(\"\\n--- 标准化后的数据 ---\")\n",
    "print(D_normalized)\n",
    "print(\"\\n--- 验证标准化后数据的均值和标准差（应接近0和1）---\")\n",
    "print(\"新均值:\", D_normalized.mean(dim=0))\n",
    "print(\"新标准差:\", D_normalized.std(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50. 终极挑战：模拟Vision Transformer的图像分块与分析 (★★★)\n",
    "- 背景: Vision Transformer (ViT) 是一种在图像识别领域取得巨大成功的模型。它颠覆了传统卷积网络（CNN）的思路，将图像分割成一系列固定大小的“图块”(Patches)，然后将这些图块的序列输入到Transformer模型中进行学习。这个挑战将模拟ViT模型中最关键、最巧妙的第一步：图像分块 (Image Patching)，并对分块结果进行简单的分析。\n",
    "\n",
    "- 任务: 给定一个模拟的 32x32 RGB图像，你需要不使用任何Python循环，仅通过张量操作将其分割成 4x4 大小的图块，并找出“最亮”的那个图块。\n",
    "\n",
    "- 具体步骤:\n",
    "\n",
    "1. 图像分块 (张量塑形):\n",
    "   - 创建一个 (3, 32, 32) 的随机张量 image 来模拟一张RGB图像。\n",
    "   - 定义 patch_size = 4。\n",
    "   - 通过一系列的塑形和维度变换操作，将 image 张量转换成一个形状为 (64, 3, 4, 4) 的 patches 张量。这代表了 8x8=64 个图块，每个图块都是 3x4x4 的。\n",
    "2. 计算各块的平均颜色 (聚合运算):\n",
    "   - 对上一步得到的 patches 张量进行聚合运算，计算出64个图块中，每一个图块的R、G、B三个通道的颜色均值。\n",
    "   - 最终应得到一个形状为 (64, 3) 的张量 mean_colors。\n",
    "3. 寻找最亮的图块 (数学运算与查找):\n",
    "   - “亮度”可以被近似定义为颜色向量的强度。请计算 mean_colors 张量中每一个图块的颜色向量（长度为3）的 L2范数。\n",
    "   - 找出L2范数最大的那个图块，并返回它在64个图块中的 索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 任务设定 ---\n",
      "原始图像形状: torch.Size([3, 32, 32])\n",
      "图块大小: 4x4\n",
      "\n",
      "--- 1. 图像分块结果 ---\n",
      "分块后张量形状: torch.Size([64, 3, 4, 4])\n",
      "共得到 64 个 4x4 的图块。\n",
      "\n",
      "--- 2. 各图块的平均颜色 ---\n",
      "平均颜色张量形状: torch.Size([64, 3])\n",
      "前5个图块的平均R,G,B值:\n",
      "tensor([[140.5000, 120.0000, 112.1250],\n",
      "        [ 86.5000, 108.6250, 154.4375],\n",
      "        [145.4375, 106.0625, 142.2500],\n",
      "        [123.7500, 125.8750, 122.8750],\n",
      "        [130.2500, 114.1875,  94.1875]])\n",
      "\n",
      "--- 3. 寻找最亮的图块 ---\n",
      "每个图块的亮度(L2范数):\n",
      "tensor([216.1302, 207.6839, 229.4262, 215.0740, 197.1678, 264.0987, 214.4895,\n",
      "        237.5283, 210.7780, 227.2983, 222.4846, 256.0205, 273.3630, 228.7893,\n",
      "        230.9097, 196.8072, 195.3281, 212.8864, 231.6634, 206.6679, 235.8289,\n",
      "        259.5774, 207.3605, 227.7825, 204.3258, 194.4541, 216.9226, 195.8058,\n",
      "        201.0884, 240.1360, 229.5229, 207.2234, 220.3880, 207.2952, 228.2402,\n",
      "        245.2392, 211.3525, 191.8025, 250.3566, 230.7233, 224.6295, 228.2636,\n",
      "        228.7965, 203.7335, 198.0699, 242.1788, 259.8570, 230.5771, 207.8853,\n",
      "        210.4995, 255.8450, 208.7542, 230.8481, 247.0584, 226.0972, 239.1875,\n",
      "        225.8618, 193.7221, 187.6368, 245.0456, 217.1308, 192.1367, 226.2981,\n",
      "        203.4558])\n",
      "\n",
      "最亮的图块索引是: 12\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以保证结果可复现\n",
    "torch.manual_seed(88)\n",
    "\n",
    "# 创建一个模拟的 32x32 RGB图像，值范围在0-255之间\n",
    "image = torch.randint(0, 256, (3, 32, 32), dtype=torch.float)\n",
    "patch_size = 4\n",
    "num_patches_per_dim = image.shape[1] // patch_size\n",
    "\n",
    "print(f\"--- 任务设定 ---\")\n",
    "print(f\"原始图像形状: {image.shape}\")\n",
    "print(f\"图块大小: {patch_size}x{patch_size}\")\n",
    "\n",
    "# --- 1. 图像分块 (核心步骤) ---\n",
    "# 这是一个非常巧妙的、无需循环的张量操作技巧\n",
    "# a. 将H和W维度分割成 (num_patches, patch_size)\n",
    "# (3, 32, 32) -> (3, 8*8, 4, 4)\n",
    "patches_temp = image.view(\n",
    "    3,\n",
    "    num_patches_per_dim**2,\n",
    "    patch_size,\n",
    "    patch_size\n",
    ")\n",
    "# b. 交换维度\n",
    "patches = patches_temp.transpose(0, 1)\n",
    "\n",
    "print(\"\\n--- 1. 图像分块结果 ---\")\n",
    "print(f\"分块后张量形状: {patches.shape}\")\n",
    "print(f\"共得到 {patches.shape[0]} 个 {patches.shape[2]}x{patches.shape[3]} 的图块。\")\n",
    "\n",
    "\n",
    "# --- 2. 计算各块的平均颜色 ---\n",
    "# 对每个图块的 H 和 W 维度求均值\n",
    "# 输入: (64, 3, 4, 4) -> 输出: (64, 3)\n",
    "mean_colors = patches.mean(dim=(-1, -2)) # -1和-2代表最后两个维度(H, W)\n",
    "\n",
    "print(\"\\n--- 2. 各图块的平均颜色 ---\")\n",
    "print(f\"平均颜色张量形状: {mean_colors.shape}\")\n",
    "print(\"前5个图块的平均R,G,B值:\")\n",
    "print(mean_colors[:5, :])\n",
    "\n",
    "# --- 3. 寻找最亮的图块 ---\n",
    "# 计算每个颜色向量的L2范数\n",
    "# 输入: (64, 3) -> 输出: (64,)\n",
    "brightness = torch.norm(mean_colors, p=2, dim=1)\n",
    "# 找到范数最大值的索引\n",
    "brightest_patch_index = torch.argmax(brightness)\n",
    "\n",
    "print(\"\\n--- 3. 寻找最亮的图块 ---\")\n",
    "print(f\"每个图块的亮度(L2范数):\")\n",
    "print(brightness)\n",
    "print(f\"\\n最亮的图块索引是: {brightest_patch_index.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模块四：广播机制 📡\n",
    "目标: 深入理解当两个形状不同的张量进行运算时，PyTorch 如何自动扩展维度来匹配形状。这是写出简洁、高效、强大代码的关键。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 51. 广播初体验：矩阵与向量相加 (★★☆)\n",
    "任务: 创建一个形状为 (3, 4) 的矩阵 A 和一个形状为 (4,) 的向量 v。将它们直接相加，观察并解释结果。请描述向量 v 是如何被“广播”以匹配矩阵 A 的每一行，并说明结果张量的形状为什么是 (3, 4)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始矩阵 A (3x4) ---\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "--- 原始向量 v (shape: 4) ---\n",
      "tensor([0, 1, 2, 3])\n",
      "\n",
      "--- 相加后的结果 (3x4) ---\n",
      "tensor([[ 0,  2,  4,  6],\n",
      "        [ 4,  6,  8, 10],\n",
      "        [ 8, 10, 12, 14]])\n",
      "结果形状: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建张量\n",
    "A = torch.arange(12).reshape(3, 4)\n",
    "v = torch.arange(4)\n",
    "\n",
    "print(\"--- 原始矩阵 A (3x4) ---\")\n",
    "print(A)\n",
    "print(\"\\n--- 原始向量 v (shape: 4) ---\")\n",
    "print(v)\n",
    "\n",
    "# 2. 直接相加，触发广播\n",
    "# 解释：\n",
    "# A 的形状: (3, 4)\n",
    "# v 的形状:    (4)\n",
    "# PyTorch 会自动将 v 的形状扩展为 (1, 4)，然后复制3次，使其变为 (3, 4)，再与 A 逐元素相加。\n",
    "# 整个过程在底层实现，没有实际的内存复制，非常高效。\n",
    "result = A + v\n",
    "\n",
    "print(\"\\n--- 相加后的结果 (3x4) ---\")\n",
    "print(result)\n",
    "print(f\"结果形状: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 52. 广播的核心规则：从右对齐 (★★☆)\n",
    "任务: 创建两个形状分别为 (2, 1, 4) 和 (3, 1) 的张量。请不要直接计算，而是根据广播的核心规则——“从尾部开始对齐维度，要么维度相等，要么其中一个为1”——来手动推断它们相加后的结果张量的形状，并文字说明推断过程，最后再用代码验证你的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- T1 的形状: torch.Size([2, 1, 4]) ---\n",
      "--- T2 的形状: torch.Size([3, 1]) ---\n",
      "\n",
      "--- 手动推断结果与实际计算结果对比 ---\n",
      "手动推断的形状: (2, 3, 4)\n",
      "实际计算的形状: torch.Size([2, 3, 4])\n",
      "两者是否一致: True\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建张量\n",
    "T1 = torch.randn(2, 1, 4)\n",
    "T2 = torch.randn(3, 1)\n",
    "\n",
    "print(f\"--- T1 的形状: {T1.shape} ---\")\n",
    "print(f\"--- T2 的形状: {T2.shape} ---\")\n",
    "\n",
    "# 2. 手动推断过程\n",
    "#   T1 shape:  (2, 1, 4)\n",
    "#   T2 shape:      (3, 1)  <- 从右向左对齐\n",
    "#   --------------------\n",
    "# -> 维度2:     4 vs 1   (OK, 1可以广播到4)  -> 结果维度为 4\n",
    "# -> 维度1:     1 vs 3   (OK, 1可以广播到3)  -> 结果维度为 3\n",
    "# -> 维度0:     2 vs (空) (OK, 空可以广播到2) -> 结果维度为 2\n",
    "#   --------------------\n",
    "#   推断结果形状: (2, 3, 4)\n",
    "\n",
    "# 3. 实际计算并验证\n",
    "result = T1 + T2\n",
    "print(\"\\n--- 手动推断结果与实际计算结果对比 ---\")\n",
    "print(f\"手动推断的形状: (2, 3, 4)\")\n",
    "print(f\"实际计算的形状: {result.shape}\")\n",
    "print(f\"两者是否一致: {result.shape == torch.Size([2, 3, 4])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 53. 广播的边界：何时会失败？ (★★☆)\n",
    "任务: 创建两个形状不兼容的张量，例如 (3, 4) 和 (3,)。尝试将它们相加，程序会报错。请解释为什么在这种情况下广播机制会失败，并与第51题中的成功案例进行对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 尝试相加的两个张量形状 ---\n",
      "A 的形状: torch.Size([3, 4])\n",
      "v 的形状: torch.Size([3])\n",
      "\n",
      "--- 操作失败，捕获到 RuntimeError ---\n",
      "错误信息: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1\n",
      "\n",
      "--- 失败原因分析 ---\n",
      "将两个形状从右对齐：\n",
      "  A shape: (3, 4)\n",
      "  v shape:    (3)\n",
      "在最右边的维度上，4 和 3 不相等，且两者都不为1，因此无法广播，导致计算失败。\n",
      "对比第51题，向量长度为4，与矩阵的列数匹配，所以可以广播。\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建形状不兼容的张量\n",
    "A = torch.randn(3, 4)\n",
    "v = torch.randn(3)\n",
    "\n",
    "print(f\"--- 尝试相加的两个张量形状 ---\")\n",
    "print(f\"A 的形状: {A.shape}\")\n",
    "print(f\"v 的形状: {v.shape}\")\n",
    "\n",
    "# 2. 尝试相加并捕获错误\n",
    "try:\n",
    "    result = A + v\n",
    "except RuntimeError as e:\n",
    "    print(\"\\n--- 操作失败，捕获到 RuntimeError ---\")\n",
    "    print(f\"错误信息: {e}\")\n",
    "    print(\"\\n--- 失败原因分析 ---\")\n",
    "    print(\"将两个形状从右对齐：\")\n",
    "    print(\"  A shape: (3, 4)\")\n",
    "    print(\"  v shape:    (3)\")\n",
    "    print(\"在最右边的维度上，4 和 3 不相等，且两者都不为1，因此无法广播，导致计算失败。\")\n",
    "    print(\"对比第51题，向量长度为4，与矩阵的列数匹配，所以可以广播。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 54. 实用案例：数据标准化 (★★☆)\n",
    "任务: 创建一个形状为 (10, 5) 的随机数据张量 D，模拟10个样本，每个样本有5个特征。计算 D 每一列（每个特征）的均值 mean 和标准差 std，它们都将是形状为 (5,) 的向量。使用广播机制，从原始数据 D 中减去均值 mean 并除以标准差 std，以完成 Z-Score 标准化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始数据 D (10x5) ---\n",
      "tensor([[5.6700, 6.4700, 9.8900, 6.4400, 3.2800],\n",
      "        [8.2600, 6.8000, 4.8800, 2.0300, 5.6000],\n",
      "        [0.4800, 1.6400, 1.5400, 7.4500, 8.7200],\n",
      "        [5.4300, 9.0000, 5.0400, 5.9200, 0.0200],\n",
      "        [2.4000, 9.6700, 6.2700, 8.5000, 5.4600],\n",
      "        [7.0300, 3.7900, 0.4300, 8.8100, 4.0700],\n",
      "        [1.2600, 8.1700, 2.3200, 8.9200, 8.0800],\n",
      "        [4.5900, 3.7600, 0.8000, 2.2100, 2.8200],\n",
      "        [8.1600, 6.4900, 0.2900, 5.6100, 8.9800],\n",
      "        [2.0900, 9.4000, 9.5000, 7.6400, 3.8400]])\n",
      "\n",
      "--- 每列的均值 (shape: torch.Size([5])) ---\n",
      "tensor([4.5400, 6.5200, 4.1000, 6.3500, 5.0900])\n",
      "\n",
      "--- 每列的标准差 (shape: torch.Size([5])) ---\n",
      "tensor([2.8500, 2.7100, 3.6200, 2.5100, 2.8700])\n",
      "\n",
      "--- 标准化后的数据 D_normalized ---\n",
      "tensor([[ 0.4000, -0.0200,  1.6000,  0.0400, -0.6300],\n",
      "        [ 1.3100,  0.1100,  0.2200, -1.7200,  0.1800],\n",
      "        [-1.4300, -1.8000, -0.7100,  0.4400,  1.2600],\n",
      "        [ 0.3100,  0.9200,  0.2600, -0.1700, -1.7600],\n",
      "        [-0.7500,  1.1600,  0.6000,  0.8600,  0.1300],\n",
      "        [ 0.8800, -1.0100, -1.0100,  0.9800, -0.3500],\n",
      "        [-1.1500,  0.6100, -0.4900,  1.0200,  1.0400],\n",
      "        [ 0.0200, -1.0200, -0.9100, -1.6500, -0.7900],\n",
      "        [ 1.2700, -0.0100, -1.0500, -0.3000,  1.3600],\n",
      "        [-0.8600,  1.0600,  1.5000,  0.5100, -0.4300]])\n",
      "\n",
      "--- 验证标准化后数据的均值和标准差 ---\n",
      "新均值: tensor([-0., -0., 0., 0., -0.])\n",
      "新标准差: tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(54)\n",
    "\n",
    "# 1. 创建数据\n",
    "D = torch.rand(10, 5) * 10  # 放大数值范围\n",
    "print(\"--- 原始数据 D (10x5) ---\")\n",
    "print(D.round(decimals=2)) # decimals=2 表示将数值四舍五入到小数点后 2 位\n",
    "\n",
    "# 2. 计算每列的均值和标准差\n",
    "mean = D.mean(dim=0)\n",
    "std = D.std(dim=0)\n",
    "print(f\"\\n--- 每列的均值 (shape: {mean.shape}) ---\")\n",
    "print(mean.round(decimals=2))\n",
    "print(f\"\\n--- 每列的标准差 (shape: {std.shape}) ---\")\n",
    "print(std.round(decimals=2))\n",
    "\n",
    "\n",
    "# 3. 使用广播进行标准化\n",
    "# D(10, 5) - mean(5,)\n",
    "# D(10, 5) / std(5,)\n",
    "# mean和std被自动广播到 (10, 5) 的形状，以匹配D\n",
    "D_normalized = (D - mean) / (std + 1e-8) # 加一个极小值防止除以零\n",
    "\n",
    "print(\"\\n--- 标准化后的数据 D_normalized ---\")\n",
    "print(D_normalized.round(decimals=2))\n",
    "\n",
    "# 4. 验证\n",
    "print(\"\\n--- 验证标准化后数据的均值和标准差 ---\")\n",
    "# 均值应接近0，标准差应接近1\n",
    "print(\"新均值:\", D_normalized.mean(dim=0).round(decimals=2))\n",
    "print(\"新标准差:\", D_normalized.std(dim=0).round(decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 55. 神经网络中的应用：添加偏置项 (★★☆)\n",
    "任务: 模拟在卷积神经网络中为一个批次的特征图 (Feature Map) 添加偏置 (Bias) 的过程。创建一个形状为 (N, C, H, W) 的随机张量，例如 (4, 3, 10, 10)，代表一个批次的4张、3通道的10x10图像。再创建一个形状为 (C,) 的偏置向量，例如 (3,)。请利用广播机制，将这个偏置向量正确地加到批次中每一张图像的对应通道上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始特征图形状: torch.Size([4, 3, 10, 10]) ---\n",
      "--- 偏置向量形状: torch.Size([3]) ---\n",
      "\n",
      "--- Reshape后的偏置形状: torch.Size([1, 3, 1, 1]) ---\n",
      "--- 添加偏置后的结果形状: torch.Size([4, 3, 10, 10]) ---\n",
      "\n",
      "--- 验证通道0: 增加的偏置值是否都接近 0.1000 ---\n",
      "实际增加的偏置均值: 0.1000\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建模拟数据和偏置\n",
    "N, C, H, W = 4, 3, 10, 10\n",
    "feature_maps = torch.randn(N, C, H, W)\n",
    "bias = torch.tensor([0.1, 0.2, 0.3]) # 3个通道的偏置\n",
    "\n",
    "print(f\"--- 原始特征图形状: {feature_maps.shape} ---\")\n",
    "print(f\"--- 偏置向量形状: {bias.shape} ---\")\n",
    "\n",
    "# 2. 调整偏置形状以利用广播\n",
    "# 目标: 将 (3,) 的 bias 加到 (4, 3, 10, 10) 的 feature_maps 上\n",
    "# 我们需要将 bias 的形状对齐到 feature_maps 的通道(C)维度\n",
    "#   feature_maps shape: (N, C, H, W)\n",
    "#   bias shape:             (C)\n",
    "# 直接相加会失败。我们需要手动将 bias 变形为 (1, C, 1, 1)\n",
    "bias_reshaped = bias.view(1, C, 1, 1)\n",
    "print(f\"\\n--- Reshape后的偏置形状: {bias_reshaped.shape} ---\")\n",
    "\n",
    "# 3. 相加\n",
    "#   feature_maps shape: (4, 3, 10, 10)\n",
    "#   bias_reshaped shape:  (1, 3,  1,  1)\n",
    "# 广播后，bias_reshaped 会扩展为 (4, 3, 10, 10)\n",
    "result = feature_maps + bias_reshaped\n",
    "print(f\"--- 添加偏置后的结果形状: {result.shape} ---\")\n",
    "\n",
    "# 验证: 检查第一个样本，第一个通道的所有值是否都增加了 bias[0]\n",
    "original_slice = feature_maps[0, 0, :, :]\n",
    "result_slice = result[0, 0, :, :]\n",
    "bias_added = result_slice - original_slice\n",
    "print(f\"\\n--- 验证通道0: 增加的偏置值是否都为 {bias[0].item():.4f} ---\")\n",
    "# 由于浮点数精度，我们检查均值\n",
    "print(f\"实际增加的偏置均值: {bias_added.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 56. 向量外积的实现 (★★★)\n",
    "任务: 给定两个一维向量，v1 长度为 m，v2 长度为 n。请不使用 torch.outer 函数，而是通过调整它们的形状（例如使用 unsqueeze 或 view）并利用广播机制，计算它们的乘积，从而得到一个形状为 (m, n) 的外积矩阵。\n",
    "\n",
    "- 外积（Outer Product）的定义：\n",
    "    - 对于两个向量 v1 = [v₁, v₂, ..., vₘ] 和 v2 = [w₁, w₂, ..., wₙ]\n",
    "    - 它们的外积结果是一个 m×n 的矩阵，其中第 i 行第 j 列的元素是 vᵢ × wⱼ\n",
    "    - 也就是说，结果矩阵的每个元素是两个向量对应位置元素的乘积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 向量 v1 (长度 3) ---\n",
      "tensor([1, 2, 3])\n",
      "\n",
      "--- 向量 v2 (长度 5) ---\n",
      "tensor([1, 2, 3, 4, 5])\n",
      "\n",
      "--- 解法一：使用广播计算外积 (3x5) ---\n",
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 2,  4,  6,  8, 10],\n",
      "        [ 3,  6,  9, 12, 15]])\n",
      "\n",
      "--- 解法二：使用 torch.outer 计算外积 (3x5) ---\n",
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 2,  4,  6,  8, 10],\n",
      "        [ 3,  6,  9, 12, 15]])\n",
      "\n",
      "两种方法结果是否相同: True\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建向量\n",
    "m, n = 3, 5\n",
    "v1 = torch.arange(1, m + 1)\n",
    "v2 = torch.arange(1, n + 1)\n",
    "print(f\"--- 向量 v1 (长度 {m}) ---\")\n",
    "print(v1)\n",
    "print(f\"\\n--- 向量 v2 (长度 {n}) ---\")\n",
    "print(v2)\n",
    "\n",
    "# --- 解法一：使用广播（标准答案） ---\n",
    "# 将 v1 变为列向量 (m, 1)，v2 变为行向量 (1, n)\n",
    "v1_col = v1.unsqueeze(1)  # shape: (3, 1)\n",
    "v2_row = v2.unsqueeze(0)  # shape: (1, 5)\n",
    "\n",
    "# v1_col (3, 1) * v2_row (1, 5) -> 广播后 (3, 5) * (3, 5)\n",
    "outer_prod_broadcast = v1_col * v2_row\n",
    "print(\"\\n--- 解法一：使用广播计算外积 (3x5) ---\")\n",
    "print(outer_prod_broadcast)\n",
    "\n",
    "# --- 解法二：使用官方函数（用于对比） ---\n",
    "outer_prod_official = torch.outer(v1, v2)\n",
    "print(\"\\n--- 解法二：使用 torch.outer 计算外积 (3x5) ---\")\n",
    "print(outer_prod_official)\n",
    "\n",
    "print(f\"\\n两种方法结果是否相同: {torch.all(outer_prod_broadcast == outer_prod_official)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 57. 创建坐标网格 (★★★)\n",
    "任务: 在很多计算机视觉任务中需要为每个像素生成坐标。给定高度 H=5 和宽度 W=5，请使用 torch.arange 和广播机制，高效地生成两个 (H, W) 的张量：grid_x 和 grid_y。其中 grid_x 的每一列都是 [0, 1, 2, 3, 4]，grid_y 的每一行都是 [0, 1, 2, 3, 4]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 基础列向量 y_vec (5x1) ---\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "\n",
      "--- 基础行向量 x_vec (1x5) ---\n",
      "tensor([[0, 1, 2, 3, 4]])\n",
      "\n",
      "--- grid_y (y坐标) ---\n",
      "tensor([[0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [4, 4, 4, 4, 4]], dtype=torch.int32)\n",
      "\n",
      "--- grid_x (x坐标) ---\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]], dtype=torch.int32)\n",
      "\n",
      "--- expand 方法 grid_y ---\n",
      "tensor([[0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [4, 4, 4, 4, 4]])\n",
      "\n",
      "--- expand 方法 grid_x ---\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n",
      "\n",
      "--- meshgrid 方法 grid_y ---\n",
      "tensor([[0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [4, 4, 4, 4, 4]])\n",
      "\n",
      "--- meshgrid 方法 grid_x ---\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "H, W = 5, 5\n",
    "\n",
    "# --- 解法一：使用广播（标准答案） ---\n",
    "# 1. 创建基础的列向量和行向量\n",
    "y_vec = torch.arange(H).view(H, 1) # shape: (5, 1)\n",
    "x_vec = torch.arange(W).view(1, W) # shape: (1, 5)\n",
    "\n",
    "print(\"--- 基础列向量 y_vec (5x1) ---\")\n",
    "print(y_vec)\n",
    "print(\"\\n--- 基础行向量 x_vec (1x5) ---\")\n",
    "print(x_vec)\n",
    "\n",
    "# 2. 利用广播生成网格\n",
    "# y_vec(5,1) 会被广播以匹配 x_vec(1,5) -> 结果 (5,5)\n",
    "# x_vec(1,5) 会被广播以匹配 y_vec(5,1) -> 结果 (5,5)\n",
    "# 添加一个全零张量可以更清晰地展示广播过程\n",
    "zeros_y = torch.zeros(1, W)\n",
    "zeros_x = torch.zeros(H, 1)\n",
    "grid_y = y_vec + zeros_y\n",
    "grid_x = x_vec + zeros_x\n",
    "\n",
    "print(\"\\n--- grid_y (y坐标) ---\")\n",
    "print(grid_y.int())\n",
    "print(\"\\n--- grid_x (x坐标) ---\")\n",
    "print(grid_x.int())\n",
    "\n",
    "\n",
    "# --- 解法二：使用 expand 函数（原理相通）---\n",
    "# expand 不会分配新内存，依赖于修改张量的stride信息，原理与广播类似\n",
    "y_vec_exp = torch.arange(H).view(H, 1).expand(H, W)\n",
    "x_vec_exp = torch.arange(W).view(1, W).expand(H, W)\n",
    "print(\"\\n--- expand 方法 grid_y ---\")\n",
    "print(y_vec_exp)\n",
    "print(\"\\n--- expand 方法 grid_x ---\")\n",
    "print(x_vec_exp)\n",
    "\n",
    "# --- 解法三：使用 meshgrid 函数（高级API）---\n",
    "# 这是最直接的方式\n",
    "x_grid_mg, y_grid_mg = torch.meshgrid(torch.arange(H), torch.arange(W), indexing='xy')\n",
    "# y_grid_mg, x_grid_mg = torch.meshgrid(torch.arange(H), torch.arange(W), indexing='ij') # 效果相同\n",
    "print(\"\\n--- meshgrid 方法 grid_y ---\")\n",
    "print(y_grid_mg)\n",
    "print(\"\\n--- meshgrid 方法 grid_x ---\")\n",
    "print(x_grid_mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 58. 计算点集间的欧氏距离矩阵 (★★★)\n",
    "任务: 给定两组二维空间中的点集，P1 的形状为 (N, 2)（N个点），P2 的形状为 (M, 2)（M个点）。请使用广播机制一次性计算出 P1 中每个点到 P2 中每个点的欧氏距离（L2范数），最终得到一个形状为 (N, M) 的距离矩阵 D，其中 D[i, j] 表示 P1 中第 i 个点到 P2 中第 j 个点的距离。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 点集 P1 (shape: torch.Size([3, 2])) ---\n",
      "tensor([[5., 2.],\n",
      "        [7., 3.],\n",
      "        [8., 9.]])\n",
      "\n",
      "--- 点集 P2 (shape: torch.Size([4, 2])) ---\n",
      "tensor([[5., 0.],\n",
      "        [5., 5.],\n",
      "        [2., 1.],\n",
      "        [4., 6.]])\n",
      "\n",
      "--- 广播后差值张量的形状: torch.Size([3, 4, 2]) ---\n",
      "\n",
      "--- 最终的距离矩阵 D (shape: torch.Size([3, 4])) ---\n",
      "tensor([[ 2.0000,  3.0000,  3.1600,  4.1200],\n",
      "        [ 3.6100,  2.8300,  5.3900,  4.2400],\n",
      "        [ 9.4900,  5.0000, 10.0000,  5.0000]])\n",
      "\n",
      "--- 手动验证 P1[0] 到 P2[0] 的距离 ---\n",
      "广播计算结果: 2.0000\n",
      "手动计算结果: 2.0000\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建两组点\n",
    "torch.manual_seed(58)\n",
    "N, M = 3, 4\n",
    "P1 = torch.randint(0, 10, (N, 2)).float()\n",
    "P2 = torch.randint(0, 10, (M, 2)).float()\n",
    "\n",
    "print(f\"--- 点集 P1 (shape: {P1.shape}) ---\")\n",
    "print(P1)\n",
    "print(f\"\\n--- 点集 P2 (shape: {P2.shape}) ---\")\n",
    "print(P2)\n",
    "\n",
    "# 2. 调整形状以进行广播\n",
    "# P1: (N, 2) -> (N, 1, 2)\n",
    "# P2: (M, 2) -> (1, M, 2)\n",
    "P1_expanded = P1.unsqueeze(1)\n",
    "P2_expanded = P2.unsqueeze(0)\n",
    "\n",
    "# 3. 计算差值\n",
    "# (N, 1, 2) - (1, M, 2) -> 广播后得到 (N, M, 2)\n",
    "# 这个张量存储了 P1 中每个点与 P2 中每个点在 x, y 上的差值\n",
    "diff = P1_expanded - P2_expanded\n",
    "print(f\"\\n--- 广播后差值张量的形状: {diff.shape} ---\")\n",
    "\n",
    "# 4. 计算欧氏距离\n",
    "# 欧氏距离 = sqrt(dx^2 + dy^2)，等价于向量的L2范数\n",
    "# 沿着最后一个维度（坐标维度, dim=2）计算L2范数\n",
    "distances = torch.norm(diff, p=2, dim=2)\n",
    "\n",
    "print(f\"\\n--- 最终的距离矩阵 D (shape: {distances.shape}) ---\")\n",
    "print(distances.round(decimals=2))\n",
    "\n",
    "# 验证: 手动计算 P1[0] 到 P2[0] 的距离\n",
    "manual_dist = torch.sqrt(torch.sum((P1[0] - P2[0])**2))\n",
    "print(f\"\\n--- 手动验证 P1[0] 到 P2[0] 的距离 ---\")\n",
    "print(f\"广播计算结果: {distances[0, 0]:.4f}\")\n",
    "print(f\"手动计算结果: {manual_dist:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 59. 广播与条件掩码 (★★★)\n",
    "任务: 创建一个 (5, 5) 的随机整数矩阵。再创建一个形状为 (5,) 的一维张量，作为每一列的“阈值”。利用广播，生成一个布尔掩码，标记出矩阵中所有大于其所在列阈值的元素。最后，使用这个掩码将这些被标记的元素值修改为-1。最后只添加一行代码，使这个列阈值变为行阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始矩阵 (5x5) ---\n",
      "tensor([[13, 16, 13,  7,  3],\n",
      "        [15, 17,  1, 12, 15],\n",
      "        [11,  4,  7, 19,  1],\n",
      "        [ 2,  5, 12,  9, 16],\n",
      "        [13,  2, 14, 17, 19]])\n",
      "\n",
      "--- 列阈值向量 (shape: torch.Size([5])) ---\n",
      "tensor([15, 10,  5,  0, 18])\n",
      "\n",
      "--- 生成的布尔掩码 ---\n",
      "tensor([[False,  True,  True,  True, False],\n",
      "        [False,  True, False,  True, False],\n",
      "        [False, False,  True,  True, False],\n",
      "        [False, False,  True,  True, False],\n",
      "        [False, False,  True,  True,  True]])\n",
      "\n",
      "--- 解法一 (索引赋值) 的结果 ---\n",
      "tensor([[13, -1, -1, -1,  3],\n",
      "        [15, -1,  1, -1, 15],\n",
      "        [11,  4, -1, -1,  1],\n",
      "        [ 2,  5, -1, -1, 16],\n",
      "        [13,  2, -1, -1, -1]])\n",
      "\n",
      "--- 解法二 (masked_fill_) 的结果 ---\n",
      "tensor([[13, -1, -1, -1,  3],\n",
      "        [15, -1,  1, -1, 15],\n",
      "        [11,  4, -1, -1,  1],\n",
      "        [ 2,  5, -1, -1, 16],\n",
      "        [13,  2, -1, -1, -1]])\n",
      "\n",
      "--- 解法一 (索引赋值) 的结果 ---\n",
      "tensor([[13, -1, 13,  7,  3],\n",
      "        [-1, -1,  1, -1, -1],\n",
      "        [-1,  4, -1, -1,  1],\n",
      "        [-1, -1, -1, -1, -1],\n",
      "        [13,  2, 14, 17, -1]])\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建数据\n",
    "torch.manual_seed(59)\n",
    "matrix = torch.randint(0, 20, (5, 5))\n",
    "thresholds = torch.tensor([15, 10, 5, 0, 18])\n",
    "\n",
    "print(\"--- 原始矩阵 (5x5) ---\")\n",
    "print(matrix)\n",
    "print(f\"\\n--- 列阈值向量 (shape: {thresholds.shape}) ---\")\n",
    "print(thresholds)\n",
    "\n",
    "# 2. 利用广播生成布尔掩码\n",
    "#   matrix shape: (5, 5)\n",
    "#   thresholds shape: (5,)\n",
    "# 广播机制将 thresholds (行向量) 扩展为 (5, 5) 来匹配 matrix\n",
    "mask = matrix > thresholds\n",
    "print(\"\\n--- 生成的布尔掩码 ---\")\n",
    "print(mask)\n",
    "\n",
    "# 3. 使用掩码进行赋值\n",
    "# --- 解法一：使用索引（更常见） ---\n",
    "result1 = matrix.clone() # 创建副本以保留原始矩阵\n",
    "result1[mask] = -1\n",
    "print(\"\\n--- 解法一 (索引赋值) 的结果 ---\")\n",
    "print(result1)\n",
    "\n",
    "# --- 解法二：使用 masked_fill_ ---\n",
    "result2 = matrix.clone()\n",
    "result2.masked_fill_(mask, -1)\n",
    "print(\"\\n--- 解法二 (masked_fill_) 的结果 ---\")\n",
    "print(result2)\n",
    "\n",
    "# ---变为行阈值---\n",
    "thresholds = thresholds.unsqueeze(1)\n",
    "mask = matrix > thresholds\n",
    "result1 = matrix.clone()\n",
    "result1[mask] = -1\n",
    "print(\"\\n--- 解法一 (索引赋值) 的结果 ---\")\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 60. 批量样本加权 (★★★)\n",
    "任务: 假设你有一个批次的数据，形状为 (N, F)，其中 N 是样本数，F 是特征数。同时你有一个权重向量 w，形状为 (N,)，代表需要对每个样本施加不同的重要性权重。请使用广播，将 w 应用于数据批次，使得数据的每一行（每个样本）都乘以其对应的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始数据 (shape: torch.Size([4, 3])) ---\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "--- 样本权重 (shape: torch.Size([4])) ---\n",
      "tensor([1., 2., 3., 4.])\n",
      "\n",
      "--- Reshape后的权重形状: torch.Size([4, 1]) ---\n",
      "\n",
      "--- 加权后的数据 ---\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [4., 4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建数据和权重\n",
    "N, F = 4, 3\n",
    "data = torch.ones(N, F)\n",
    "weights = torch.arange(1, N + 1).float() # [1., 2., 3., 4.]\n",
    "\n",
    "print(f\"--- 原始数据 (shape: {data.shape}) ---\")\n",
    "print(data)\n",
    "print(f\"\\n--- 样本权重 (shape: {weights.shape}) ---\")\n",
    "print(weights)\n",
    "\n",
    "# 2. 调整权重形状以进行广播\n",
    "#   data shape: (N, F) -> (4, 3)\n",
    "#   weights shape:  (N,) -> (4,)\n",
    "# 直接相乘会报错，因为从右对齐后维度 3 和 4 不匹配\n",
    "# 我们需要将 weights 变为列向量 (N, 1)\n",
    "weights_col = weights.unsqueeze(1) # shape (4, 1)\n",
    "print(f\"\\n--- Reshape后的权重形状: {weights_col.shape} ---\")\n",
    "\n",
    "# 3. 应用权重\n",
    "#   data shape: (4, 3)\n",
    "#   weights_col shape: (4, 1)\n",
    "# 广播后，weights_col 的第2个维度会扩展为3，与 data 匹配\n",
    "weighted_data = data * weights_col\n",
    "print(\"\\n--- 加权后的数据 ---\")\n",
    "print(weighted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 61. 按特征加权 (★★★)\n",
    "任务: 与上一题类似，你有一个数据批次 (N, F)。但这次你的权重向量 w 的形状是 (F,)，代表需要对每个特征施加不同的权重。请使用广播，将 w 应用于数据批次，使得数据的每一列（每个特征）都乘以其对应的权重。比较此操作与上一题的区别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始数据 (shape: torch.Size([4, 3])) ---\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "--- 特征权重 (shape: torch.Size([3])) ---\n",
      "tensor([10., 11., 12.])\n",
      "\n",
      "--- 加权后的数据 ---\n",
      "tensor([[10., 11., 12.],\n",
      "        [10., 11., 12.],\n",
      "        [10., 11., 12.],\n",
      "        [10., 11., 12.]])\n",
      "\n",
      "--- 与上一题对比 ---\n",
      "本题中，权重向量的形状(F,)与数据批次的最后一个维度(F)匹配，\n",
      "因此广播机制可以自动将权重向量`向上`扩展，应用到每一行。\n",
      "上一题中，权重向量(N,)与数据批次任何一个维度都不直接匹配，\n",
      "必须手动将其转换为列向量(N, 1)，才能让广播机制`向右`扩展。\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建数据和权重\n",
    "N, F = 4, 3\n",
    "data = torch.ones(N, F)\n",
    "weights = torch.arange(10, 10 + F).float() # [10., 11., 12.]\n",
    "\n",
    "print(f\"--- 原始数据 (shape: {data.shape}) ---\")\n",
    "print(data)\n",
    "print(f\"\\n--- 特征权重 (shape: {weights.shape}) ---\")\n",
    "print(weights)\n",
    "\n",
    "# 2. 直接应用权重，无需调整形状\n",
    "#   data shape: (N, F) -> (4, 3)\n",
    "#   weights shape:  (F,) ->   (3)\n",
    "# 从右对齐，维度匹配。weights 会被广播到 (4, 3)\n",
    "weighted_data = data * weights\n",
    "print(\"\\n--- 加权后的数据 ---\")\n",
    "print(weighted_data)\n",
    "\n",
    "print(\"\\n--- 与上一题对比 ---\")\n",
    "print(\"本题中，权重向量的形状(F,)与数据批次的最后一个维度(F)匹配，\")\n",
    "print(\"因此广播机制可以自动将权重向量`向上`扩展，应用到每一行。\")\n",
    "print(\"上一题中，权重向量(N,)与数据批次任何一个维度都不直接匹配，\")\n",
    "print(\"必须手动将其转换为列向量(N, 1)，才能让广播机制`向右`扩展。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 62. 用广播模拟 torch.expand (★★★)\n",
    "任务: 创建一个形状为 (3, 1) 的张量 T。不使用 .expand() 或 .repeat() 方法，而是通过与一个全零张量进行数学运算（如加法），利用广播机制将其“扩展”为一个形状为 (3, 4) 的新张量。这个练习旨在揭示广播是很多高效操作的底层原理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始张量 T (shape: torch.Size([3, 1])) ---\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2]])\n",
      "\n",
      "--- 用于广播的全零张量 (shape: torch.Size([1, 4])) ---\n",
      "tensor([[0., 0., 0., 0.]])\n",
      "\n",
      "--- 通过广播扩展后的张量 (shape: torch.Size([3, 4])) ---\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.]])\n",
      "\n",
      "--- 原理解释 ---\n",
      "加0不改变原始值，但这个操作触发了广播机制。\n",
      "PyTorch 根据两个张量的形状计算出了一个共同的目标形状 (3, 4)，\n",
      "并创建了一个具有该形状的新视图，其内容由 T 和 zeros 决定。\n",
      "这与 expand 的行为在结果上是等价的，且同样高效。\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建原始张量\n",
    "T = torch.arange(3).view(3, 1)\n",
    "print(f\"--- 原始张量 T (shape: {T.shape}) ---\")\n",
    "print(T)\n",
    "\n",
    "# 2. 创建一个用于广播的全零张量\n",
    "# 它的形状需要能和 T 广播成目标形状 (3, 4)\n",
    "zeros = torch.zeros(1, 4)\n",
    "print(f\"\\n--- 用于广播的全零张量 (shape: {zeros.shape}) ---\")\n",
    "print(zeros)\n",
    "\n",
    "# 3. 通过加法触发广播\n",
    "#   T shape: (3, 1)\n",
    "#   zeros shape: (1, 4)\n",
    "#   广播结果 shape: (3, 4)\n",
    "expanded_T = T + zeros\n",
    "print(f\"\\n--- 通过广播扩展后的张量 (shape: {expanded_T.shape}) ---\")\n",
    "print(expanded_T)\n",
    "\n",
    "print(\"\\n--- 原理解释 ---\")\n",
    "print(\"加0不改变原始值，但这个操作触发了广播机制。\")\n",
    "print(\"PyTorch 根据两个张量的形状计算出了一个共同的目标形状 (3, 4)，\")\n",
    "print(\"并创建了一个具有该形状的新视图，其内容由 T 和 zeros 决定。\")\n",
    "print(\"这与 expand 的行为在结果上是等价的，且同样高效。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 63. 模拟注意力机制中的掩码相加 (★★★)\n",
    "任务: 在 Transformer 解码器的自注意力计算中，为了防止看到未来的信息，需要给注意力分数矩阵加上一个掩码。假设你有一个注意力分数矩阵 scores，形状为 (Batch, Heads, SeqLen, SeqLen)，例如 (4, 8, 10, 10)。请完成以下任务：\n",
    "\n",
    "1. 创建一个未来信息掩码，使得每个位置只能看到当前位置及之前的信息\n",
    "2. 将掩码应用到注意力分数上，使得被掩码的位置的注意力分数变为一个很小的负数（如 -1e9）\n",
    "\n",
    "提示：\n",
    "- 未来信息掩码应该是一个上三角矩阵\n",
    "- 考虑掩码的形状应该如何设计才能正确广播到注意力分数上\n",
    "- 思考为什么掩码中的 0 和 1 需要转换为 0 和 -1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 注意力分数 scores 形状: torch.Size([4, 8, 10, 10]) ---\n",
      "--- 未来信息掩码 ---\n",
      "tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "--- 添加掩码后的分数张量形状: torch.Size([4, 8, 10, 10]) ---\n",
      "\n",
      "--- 添加掩码后的分数张量(第一个样本的第一个头):\n",
      " tensor([[-1.1365e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [ 7.1482e-01, -8.6461e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [ 1.1399e+00,  2.7839e-01, -6.0210e-01, -1.0000e+09, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [-1.9139e-01, -1.4062e+00, -3.0345e-02, -2.9527e-01, -1.0000e+09,\n",
      "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [-4.7815e-02,  1.2845e+00,  8.0715e-01, -1.9799e-01,  1.3621e+00,\n",
      "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [ 7.3676e-01,  6.9787e-01,  1.2225e+00, -7.6528e-01,  1.7373e+00,\n",
      "         -1.7088e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [-1.3633e-01, -6.6455e-01,  1.6533e+00,  1.0652e+00, -1.2400e+00,\n",
      "          1.9683e-01,  2.0377e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "        [-7.5810e-01, -1.5938e-01,  8.6928e-01, -9.4490e-01,  3.7053e-01,\n",
      "         -1.0537e+00, -9.0153e-01,  5.7468e-02, -1.0000e+09, -1.0000e+09],\n",
      "        [-2.5473e+00,  7.0617e-01, -1.8634e+00,  8.2933e-01,  1.4503e+00,\n",
      "         -8.3179e-01,  7.9592e-01, -7.9897e-01,  1.5307e-01, -1.0000e+09],\n",
      "        [ 2.0086e-01,  2.9139e-01,  2.2530e-02, -9.8774e-01, -1.5606e+00,\n",
      "          1.1025e+00,  1.0861e+00,  1.9311e-02,  1.8930e+00,  2.4710e-01]]) ---\n",
      "\n",
      "--- 验证结果 ---\n",
      "原始未来信息的平均值: -0.46\n",
      "掩码后未来信息的平均值: -999999936.00 (应该接近-1e9)\n",
      "原始过去信息的平均值: -0.10\n",
      "掩码后过去信息的平均值: -0.10 (应该与原始值相近)\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建模拟数据\n",
    "B, H, S = 4, 8, 10\n",
    "scores = torch.randn(B, H, S, S)\n",
    "\n",
    "print(f\"--- 注意力分数 scores 形状: {scores.shape} ---\")\n",
    "\n",
    "# 2. 创建未来信息掩码\n",
    "# 首先创建一个上三角矩阵，对角线及以上为1，其他为0\n",
    "future_mask = torch.triu(torch.ones(S, S), diagonal=1)\n",
    "\"\"\"\n",
    "[[0, 1, 1, 1],  # 第0个位置只能看到自己\n",
    " [0, 0, 1, 1],  # 第1个位置可以看到0和1\n",
    " [0, 0, 0, 1],  # 第2个位置可以看到0,1,2\n",
    " [0, 0, 0, 0]]  # 第3个位置可以看到所有\n",
    "\"\"\"\n",
    "print(\"--- 未来信息掩码 ---\")\n",
    "print(future_mask)\n",
    "\n",
    "# 将1的部分设置为-1e9\n",
    "future_mask = future_mask.masked_fill(future_mask == 1, -1e9)\n",
    "# 调整形状以匹配广播需求\n",
    "future_mask = future_mask.view(1, 1, S, S)\n",
    "\n",
    "# 3. 将掩码应用到注意力分数上\n",
    "#   scores shape: (B, H, S, S) -> (4, 8, 10, 10)\n",
    "#   mask shape:   (1, 1, S, S) -> (1, 1, 10, 10)\n",
    "# 广播后，mask 会被扩展为 (4, 8, 10, 10)\n",
    "masked_scores = scores + future_mask\n",
    "\n",
    "print(f\"\\n--- 添加掩码后的分数张量形状: {masked_scores.shape} ---\")\n",
    "print(f\"\\n--- 添加掩码后的分数张量(第一个样本的第一个头):\\n {masked_scores[0][0]} ---\")\n",
    "\n",
    "# 4. 验证\n",
    "# 检查第一个样本，第一个头的掩码效果\n",
    "# 上三角部分（未来信息）应该都是-1e9\n",
    "# 下三角部分（包括对角线）应该保持原值\n",
    "original_upper = scores[0, 0, 0, 1:].mean()  # 第一行的未来信息\n",
    "masked_upper = masked_scores[0, 0, 0, 1:].mean()  # 第一行的未来信息（应该被掩码）\n",
    "original_lower = scores[0, 0, 1:, 0].mean()  # 第一列的过去信息\n",
    "masked_lower = masked_scores[0, 0, 1:, 0].mean()  # 第一列的过去信息（应该保持不变）\n",
    "\n",
    "print(\"\\n--- 验证结果 ---\")\n",
    "print(f\"原始未来信息的平均值: {original_upper:.2f}\")\n",
    "print(f\"掩码后未来信息的平均值: {masked_upper:.2f} (应该接近-1e9)\")\n",
    "print(f\"原始过去信息的平均值: {original_lower:.2f}\")\n",
    "print(f\"掩码后过去信息的平均值: {masked_lower:.2f} (应该与原始值相近)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 64. 广播与高级赋值 (★★★)\n",
    "任务: 创建一个 (6, 6) 的全零矩阵 M。你的目标是给 M 的四个 3x3 的子块（左上、右上、左下、右下）分别加上不同的常数。创建一个 (2, 2) 的张量 V，例如 [[1, 10], [100, 1000]]。请利用广播和张量变形，将 V[0,0] 加到 M 的左上角 3x3 子块，V[0,1] 加到右上角，以此类推。（作者还没想出很完美、很优雅的解法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始矩阵 M (6x6) ---\n",
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "--- 值矩阵 V (2x2) ---\n",
      "tensor([[   1.,   10.],\n",
      "        [ 100., 1000.]])\n",
      "\n",
      "--- 最终结果 ---\n",
      "tensor([[   1.,    1.,    1.,   10.,   10.,   10.],\n",
      "        [   1.,    1.,    1.,   10.,   10.,   10.],\n",
      "        [   1.,    1.,    1.,   10.,   10.,   10.],\n",
      "        [ 100.,  100.,  100., 1000., 1000., 1000.],\n",
      "        [ 100.,  100.,  100., 1000., 1000., 1000.],\n",
      "        [ 100.,  100.,  100., 1000., 1000., 1000.]])\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建原始矩阵和值矩阵\n",
    "M = torch.zeros(6, 6)\n",
    "V = torch.tensor([[1., 10.], [100., 1000.]])\n",
    "\n",
    "print(\"--- 原始矩阵 M (6x6) ---\")\n",
    "print(M)\n",
    "print(\"\\n--- 值矩阵 V (2x2) ---\")\n",
    "print(V)\n",
    "\n",
    "# 2.将M矩阵拆分为四个子块\n",
    "M_top, M_bottom = torch.chunk(M, 2, dim=0)\n",
    "M_top_left, M_top_right = torch.chunk(M_top, 2, dim=1)\n",
    "M_bottom_left, M_bottom_right = torch.chunk(M_bottom, 2, dim=1)\n",
    "\n",
    "# 3.广播机制为整块赋值\n",
    "M_top_left = M_top_left + V[0, 0]\n",
    "M_top_right = M_top_right + V[0, 1]\n",
    "M_bottom_left = M_bottom_left + V[1, 0]\n",
    "M_bottom_right = M_bottom_right + V[1, 1]\n",
    "\n",
    "# 4. 将整块拼接起来\n",
    "M_top_new = torch.cat((M_top_left, M_top_right), dim=1)\n",
    "M_bottom_new = torch.cat((M_bottom_left, M_bottom_right), dim=1)\n",
    "M_new = torch.cat((M_top_new, M_bottom_new), dim=0)\n",
    "\n",
    "print(\"\\n--- 最终结果 ---\")\n",
    "print(M_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 65. 终极挑战：实现 Transformer 的位置编码 (★★★)\n",
    "**背景**: 经典的 Transformer 模型（源自论文《Attention Is All You Need》）在处理序列数据时，其自注意力机制本身无法感知到输入元素的顺序。为了让模型能够利用序列的位置信息，论文作者设计了一种独特的**位置编码 (Positional Encoding)** 方案。它会创建一个与输入嵌入形状相同的矩阵，然后将其直接加到输入嵌入上，从而为模型注入绝对和相对的位置信息。\n",
    "\n",
    "这种位置编码是通过不同频率的正弦和余弦函数来计算的，其公式为：\n",
    "$$PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)$$\n",
    "$$PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)$$\n",
    "其中 `pos` 是词元在序列中的位置，`i` 是编码的维度索引，`d_model` 是模型的嵌入维度。\n",
    "\n",
    "**任务**: 你的任务是利用 PyTorch，高效地生成这个位置编码矩阵。给定序列的最大长度 `max_seq_len = 100` 和模型的嵌入维度 `d_model = 64`，请完成以下步骤：\n",
    "\n",
    "1.  创建一个形状为 `(max_seq_len, 1)` 的位置张量 `position`，其值为 `0` 到 `99`。\n",
    "2.  创建一个形状为 `(d_model / 2)` 的除法项张量 `div_term`，其值为 $10000^{2i/d_{\\text{model}}}$。\n",
    "3.  利用**广播机制**，将 `position` 和 `div_term` 的信息组合起来，计算出所有 `sin` 和 `cos` 函数内部的角度参数。\n",
    "4.  分别计算正弦和余弦编码。\n",
    "5.  将正弦和余弦编码交错地合并在一起，最终生成一个形状为 `(max_seq_len, d_model)` 的完整位置编码矩阵 `pe`。\n",
    "\n",
    "请**仅使用广播和张量操作**，不使用任何显式循环来完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 目标：生成 100x64 的位置编码矩阵 ---\n",
      "\n",
      "--- 位置张量 position 的形状: torch.Size([100, 1]) ---\n",
      "\n",
      "--- 频率项 div_term 的形状: torch.Size([32]) ---\n",
      "\n",
      "--- 广播后角度矩阵 angles 的形状: torch.Size([100, 32]) ---\n",
      "\n",
      "--- 最终生成的位置编码矩阵 pe 的形状: torch.Size([100, 64]) ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# 1. 设置参数\n",
    "max_seq_len = 100\n",
    "d_model = 64\n",
    "\n",
    "print(f\"--- 目标：生成 {max_seq_len}x{d_model} 的位置编码矩阵 ---\")\n",
    "\n",
    "# 2. 创建一个全零的目标矩阵\n",
    "pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "# 3. 创建位置张量 (pos)\n",
    "# shape: (max_seq_len, 1) -> (100, 1)\n",
    "position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "print(f\"\\n--- 位置张量 position 的形状: {position.shape} ---\")\n",
    "\n",
    "# 4. 创建除法项 (10000^(2i/d_model))\n",
    "# 2i 的范围是 [0, 2, 4, ..., d_model-2]\n",
    "# div_term 旨在为不同维度提供不同的波长\n",
    "i = torch.arange(0, d_model, 2).float() # i 是维度索引的一半\n",
    "div_term = torch.pow(10000.0, i / d_model)\n",
    "print(f\"\\n--- 频率项 div_term 的形状: {div_term.shape} ---\")\n",
    "\n",
    "# 5. 计算角度参数 (pos / div_term)\n",
    "# 这是广播的核心步骤\n",
    "# position (100, 1) * (1 / div_term) (32,)\n",
    "# -> 广播后形成 (100, 32) 的角度矩阵\n",
    "angles = position / div_term\n",
    "print(f\"\\n--- 广播后角度矩阵 angles 的形状: {angles.shape} ---\")\n",
    "\n",
    "# 6. 计算正弦和余弦编码并交错填充\n",
    "# 将 sin 值填充到偶数索引列 (0, 2, 4, ...)\n",
    "pe[:, 0::2] = torch.sin(angles)\n",
    "# 将 cos 值填充到奇数索引列 (1, 3, 5, ...)\n",
    "pe[:, 1::2] = torch.cos(angles)\n",
    "\n",
    "print(f\"\\n--- 最终生成的位置编码矩阵 pe 的形状: {pe.shape} ---\")\n",
    "\n",
    "# --- 可视化位置编码 ---\n",
    "# 这是一个常见的验证方法，可以直观地看到不同维度的波长变化\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.pcolormesh(pe.numpy(), cmap='viridis')\n",
    "    plt.xlabel('Embedding Dimension')\n",
    "    plt.ylabel('Position')\n",
    "    plt.title('Positional Encoding Visualization')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"\\n未安装 matplotlib，跳过可视化。可运行 `pip install matplotlib` 来查看。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
